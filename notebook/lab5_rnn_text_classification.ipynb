{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0da57345",
      "metadata": {
        "id": "0da57345"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "d6f05e72",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'d:\\\\subject\\\\nlp\\\\code\\\\natural_language_processing\\\\notebook'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "e8bda66c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "e8bda66c",
        "outputId": "4b811df0-8fcf-4bd6-9cd1-e469968efddb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (8954, 2)\n",
            "Validation shape: (1076, 2)\n",
            "Test shape: (1076, 2)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what alarms do i have set right now</td>\n",
              "      <td>alarm_query</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>checkout today alarm of meeting</td>\n",
              "      <td>alarm_query</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>report alarm settings</td>\n",
              "      <td>alarm_query</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>see see for me the alarms that you have set to...</td>\n",
              "      <td>alarm_query</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>is there an alarm for ten am</td>\n",
              "      <td>alarm_query</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text     category\n",
              "0                what alarms do i have set right now  alarm_query\n",
              "1                    checkout today alarm of meeting  alarm_query\n",
              "2                              report alarm settings  alarm_query\n",
              "3  see see for me the alarms that you have set to...  alarm_query\n",
              "4                       is there an alarm for ten am  alarm_query"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "origin_path = r\"../data/hwu/hwu\"\n",
        "# Dữ liệu có thể được phân tách bằng tab và không có header\n",
        "df_train = pd.read_csv(os.path.join(origin_path, 'train.csv'), sep=',')\n",
        "df_val = pd.read_csv(os.path.join(origin_path, 'val.csv'), sep=',')\n",
        "df_test = pd.read_csv(os.path.join(origin_path,'test.csv'), sep=',')\n",
        "print(\"Train shape:\", df_train.shape)\n",
        "print(\"Validation shape:\", df_val.shape)\n",
        "print(\"Test shape:\", df_test.shape)\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "a28c7da4",
      "metadata": {
        "id": "a28c7da4"
      },
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "le.fit(df_train['category'])\n",
        "df_train['label'] = le.transform(df_train['category'])\n",
        "df_val['label'] = le.transform(df_val['category'])\n",
        "df_test['label'] = le.transform(df_test['category'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "7e11a0b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7e11a0b5",
        "outputId": "db4e2337-52fb-4a5d-a70c-2404aa54daea"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what alarms do i have set right now</td>\n",
              "      <td>alarm_query</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>checkout today alarm of meeting</td>\n",
              "      <td>alarm_query</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>report alarm settings</td>\n",
              "      <td>alarm_query</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>see see for me the alarms that you have set to...</td>\n",
              "      <td>alarm_query</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>is there an alarm for ten am</td>\n",
              "      <td>alarm_query</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text     category  label\n",
              "0                what alarms do i have set right now  alarm_query      0\n",
              "1                    checkout today alarm of meeting  alarm_query      0\n",
              "2                              report alarm settings  alarm_query      0\n",
              "3  see see for me the alarms that you have set to...  alarm_query      0\n",
              "4                       is there an alarm for ten am  alarm_query      0"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82fa7efc",
      "metadata": {
        "id": "82fa7efc"
      },
      "source": [
        "# TF-IDF + Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "29d15e72",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "29d15e72",
        "outputId": "96e895f7-6f64-4422-e66a-12a8ad1c4562"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.95      0.92        19\n",
            "           1       1.00      0.73      0.84        11\n",
            "           2       0.77      0.89      0.83        19\n",
            "           3       1.00      0.75      0.86         8\n",
            "           4       0.92      0.80      0.86        15\n",
            "           5       0.93      1.00      0.96        13\n",
            "           6       0.45      0.53      0.49        19\n",
            "           7       0.89      0.89      0.89        19\n",
            "           8       0.87      0.68      0.76        19\n",
            "           9       0.59      0.68      0.63        19\n",
            "          10       0.67      0.75      0.71         8\n",
            "          11       0.74      0.89      0.81        19\n",
            "          12       0.78      0.88      0.82         8\n",
            "          13       0.83      0.79      0.81        19\n",
            "          14       0.92      0.63      0.75        19\n",
            "          15       0.81      0.89      0.85        19\n",
            "          16       1.00      1.00      1.00        19\n",
            "          17       1.00      1.00      1.00        19\n",
            "          18       1.00      1.00      1.00        19\n",
            "          19       0.90      1.00      0.95        19\n",
            "          20       1.00      0.95      0.97        19\n",
            "          21       1.00      1.00      1.00        12\n",
            "          22       0.95      1.00      0.97        19\n",
            "          23       0.95      1.00      0.97        19\n",
            "          24       0.36      0.26      0.30        19\n",
            "          25       0.90      1.00      0.95        19\n",
            "          26       1.00      1.00      1.00        16\n",
            "          27       1.00      0.95      0.97        19\n",
            "          28       0.75      0.79      0.77        19\n",
            "          29       0.91      0.83      0.87        12\n",
            "          30       0.89      0.89      0.89        19\n",
            "          31       0.67      0.67      0.67         3\n",
            "          32       1.00      0.86      0.92        14\n",
            "          33       0.80      0.89      0.84         9\n",
            "          34       0.78      1.00      0.88         7\n",
            "          35       0.68      0.79      0.73        19\n",
            "          36       0.75      0.79      0.77        19\n",
            "          37       0.85      0.89      0.87        19\n",
            "          38       0.65      0.61      0.63        18\n",
            "          39       0.71      0.53      0.61        19\n",
            "          40       1.00      0.57      0.73         7\n",
            "          41       0.75      0.63      0.69        19\n",
            "          42       0.95      0.95      0.95        19\n",
            "          43       0.81      0.68      0.74        19\n",
            "          44       0.58      0.74      0.65        19\n",
            "          45       1.00      0.84      0.91        19\n",
            "          46       0.89      0.84      0.86        19\n",
            "          47       0.94      0.89      0.92        19\n",
            "          48       0.82      0.95      0.88        19\n",
            "          49       0.48      0.58      0.52        19\n",
            "          50       0.92      0.86      0.89        14\n",
            "          51       1.00      0.95      0.97        19\n",
            "          52       0.83      0.79      0.81        19\n",
            "          53       0.81      0.89      0.85        19\n",
            "          54       1.00      1.00      1.00        10\n",
            "          55       0.95      1.00      0.97        19\n",
            "          56       0.80      0.89      0.84        18\n",
            "          57       0.83      0.79      0.81        19\n",
            "          58       0.89      0.89      0.89        19\n",
            "          59       0.68      0.79      0.73        19\n",
            "          60       1.00      1.00      1.00        18\n",
            "          61       0.94      0.79      0.86        19\n",
            "          62       1.00      0.95      0.97        19\n",
            "          63       0.62      0.68      0.65        19\n",
            "\n",
            "    accuracy                           0.84      1076\n",
            "   macro avg       0.85      0.83      0.84      1076\n",
            "weighted avg       0.84      0.84      0.84      1076\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "tfidf_lr_pipeline = make_pipeline(\n",
        "    TfidfVectorizer(max_features=5000),\n",
        "    LogisticRegression(max_iter=1000)\n",
        ")\n",
        "\n",
        "tfidf_lr_pipeline.fit(df_train['text'], df_train['label'])\n",
        "y_pred = tfidf_lr_pipeline.predict(df_test['text'])\n",
        "\n",
        "print(classification_report(df_test['label'], y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99c62460",
      "metadata": {
        "id": "99c62460"
      },
      "source": [
        "# Word2Vec + Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "LKzP39P5E99W",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKzP39P5E99W",
        "outputId": "ffc7a318-415c-4bc2-ca6d-d77cc3d7b890"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "9b7985ba",
      "metadata": {
        "id": "9b7985ba"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "0f2b6fb6",
      "metadata": {
        "id": "0f2b6fb6"
      },
      "outputs": [],
      "source": [
        "# 1. Huấn luyện mô hình Word2Vec trên dữ liệu text của bạn\n",
        "sentences = [text.split() for text in df_train['text']]\n",
        "w2v_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "03c75a06",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03c75a06",
        "outputId": "70c20f73-fe1d-4453-822a-1f01626b5d37"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('alarms', 0.6348198056221008),\n",
              " ('appointment', 0.5341762900352478),\n",
              " ('appointments', 0.4859957695007324),\n",
              " ('event', 0.46934521198272705),\n",
              " ('item', 0.454486221075058),\n",
              " ('friday', 0.44339945912361145),\n",
              " ('wednesday', 0.44109663367271423),\n",
              " ('meetings', 0.44088345766067505),\n",
              " ('thursday', 0.4191473424434662),\n",
              " ('meeting', 0.4187237620353699)]"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w2v_model.wv.most_similar(\"alarm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "fd7b8171",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd7b8171",
        "outputId": "11548f0d-bf44-4ec1-94f8-41023122a460"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['alarm_query', 'alarm_remove', 'alarm_set', 'audio_volume_down',\n",
              "       'audio_volume_mute', 'audio_volume_up', 'calendar_query',\n",
              "       'calendar_remove', 'calendar_set', 'cooking_recipe',\n",
              "       'datetime_convert', 'datetime_query', 'email_addcontact',\n",
              "       'email_query', 'email_querycontact', 'email_sendemail',\n",
              "       'general_affirm', 'general_commandstop', 'general_confirm',\n",
              "       'general_dontcare', 'general_explain', 'general_joke',\n",
              "       'general_negate', 'general_praise', 'general_quirky',\n",
              "       'general_repeat', 'iot_cleaning', 'iot_coffee',\n",
              "       'iot_hue_lightchange', 'iot_hue_lightdim', 'iot_hue_lightoff',\n",
              "       'iot_hue_lighton', 'iot_hue_lightup', 'iot_wemo_off',\n",
              "       'iot_wemo_on', 'lists_createoradd', 'lists_query', 'lists_remove',\n",
              "       'music_likeness', 'music_query', 'music_settings', 'news_query',\n",
              "       'play_audiobook', 'play_game', 'play_music', 'play_podcasts',\n",
              "       'play_radio', 'qa_currency', 'qa_definition', 'qa_factoid',\n",
              "       'qa_maths', 'qa_stock', 'recommendation_events',\n",
              "       'recommendation_locations', 'recommendation_movies', 'social_post',\n",
              "       'social_query', 'takeaway_order', 'takeaway_query',\n",
              "       'transport_query', 'transport_taxi', 'transport_ticket',\n",
              "       'transport_traffic', 'weather_query'], dtype=object)"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "le.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "bd5b8073",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd5b8073",
        "outputId": "4c4a0daa-b7bd-4d27-daf7-2c498a4ba4f2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\subject\\nlp\\code\\natural_language_processing\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "def sentence_to_avg_vector(text, model):\n",
        "    tokens = text.split()\n",
        "    vectors = [model.wv[token] for token in tokens if token in model.wv]\n",
        "\n",
        "    if len(vectors) == 0:\n",
        "        # Trả về vector zero với đúng kích thước embedding\n",
        "        return np.zeros(model.vector_size, dtype='float32')\n",
        "\n",
        "    return np.mean(vectors, axis=0)\n",
        "\n",
        "def transform_to_vector(df, model):\n",
        "    # df = df.sample(frac=1, random_state=42)\n",
        "    texts = df['text'].to_list()\n",
        "    labels = df['label'].to_list()\n",
        "\n",
        "    vectors = np.array(\n",
        "        [sentence_to_avg_vector(text, model) for text in texts],\n",
        "        dtype='float32'\n",
        "    )\n",
        "    return vectors, np.array(labels)\n",
        "\n",
        "# 3. Tạo dữ liệu train/val/test X_train_avg, X_val_avg, X_test_avg\n",
        "X_train_avg, y_train = transform_to_vector(df_train, w2v_model)\n",
        "X_test_avg, y_test = transform_to_vector(df_test, w2v_model)\n",
        "X_val_avg, y_val = transform_to_vector(df_val, w2v_model)\n",
        "\n",
        "# 4. Xây dựng mô hình Sequential của Keras\n",
        "num_classes = len(le.classes_)\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(w2v_model.vector_size,)),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "f956d7c6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f956d7c6",
        "outputId": "c44384e8-34ae-4c27-d5c1-94518dcfe34c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0,  0,  0, ..., 63, 63, 63], shape=(1076,))"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "68250fa8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "68250fa8",
        "outputId": "d55a17ea-fff9-4ac2-81a8-21d079aca766"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3286 - loss: 2.7959 - val_accuracy: 0.6961 - val_loss: 1.4281\n",
            "Epoch 2/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6021 - loss: 1.4676 - val_accuracy: 0.7463 - val_loss: 0.9984\n",
            "Epoch 3/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6616 - loss: 1.2104 - val_accuracy: 0.7770 - val_loss: 0.8687\n",
            "Epoch 4/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7027 - loss: 1.0644 - val_accuracy: 0.7797 - val_loss: 0.7952\n",
            "Epoch 5/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7258 - loss: 0.9659 - val_accuracy: 0.7853 - val_loss: 0.7520\n",
            "Epoch 6/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7411 - loss: 0.9180 - val_accuracy: 0.7909 - val_loss: 0.7270\n",
            "Epoch 7/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7520 - loss: 0.8630 - val_accuracy: 0.8086 - val_loss: 0.7028\n",
            "Epoch 8/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7601 - loss: 0.8251 - val_accuracy: 0.8067 - val_loss: 0.6895\n",
            "Epoch 9/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7658 - loss: 0.8126 - val_accuracy: 0.8104 - val_loss: 0.6749\n",
            "Epoch 10/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7750 - loss: 0.7843 - val_accuracy: 0.8113 - val_loss: 0.6656\n",
            "Epoch 11/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7820 - loss: 0.7629 - val_accuracy: 0.8141 - val_loss: 0.6537\n",
            "Epoch 12/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7881 - loss: 0.7306 - val_accuracy: 0.8225 - val_loss: 0.6447\n",
            "Epoch 13/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7922 - loss: 0.7284 - val_accuracy: 0.8271 - val_loss: 0.6421\n",
            "Epoch 14/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7993 - loss: 0.6993 - val_accuracy: 0.8271 - val_loss: 0.6355\n",
            "Epoch 15/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7955 - loss: 0.6882 - val_accuracy: 0.8309 - val_loss: 0.6257\n",
            "Epoch 16/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8009 - loss: 0.6829 - val_accuracy: 0.8327 - val_loss: 0.6308\n",
            "Epoch 17/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8070 - loss: 0.6582 - val_accuracy: 0.8188 - val_loss: 0.6288\n",
            "Epoch 18/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8073 - loss: 0.6548 - val_accuracy: 0.8281 - val_loss: 0.6263\n",
            "Epoch 19/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8124 - loss: 0.6451 - val_accuracy: 0.8364 - val_loss: 0.6180\n",
            "Epoch 20/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8097 - loss: 0.6467 - val_accuracy: 0.8346 - val_loss: 0.6143\n",
            "Epoch 21/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8154 - loss: 0.6216 - val_accuracy: 0.8281 - val_loss: 0.6275\n",
            "Epoch 22/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8133 - loss: 0.6221 - val_accuracy: 0.8383 - val_loss: 0.6206\n",
            "Epoch 23/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8200 - loss: 0.6068 - val_accuracy: 0.8346 - val_loss: 0.6271\n",
            "Epoch 24/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8202 - loss: 0.6029 - val_accuracy: 0.8364 - val_loss: 0.6200\n",
            "Epoch 25/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8223 - loss: 0.5999 - val_accuracy: 0.8392 - val_loss: 0.6189\n",
            "Epoch 26/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8288 - loss: 0.5806 - val_accuracy: 0.8336 - val_loss: 0.6169\n",
            "Epoch 27/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8200 - loss: 0.5807 - val_accuracy: 0.8383 - val_loss: 0.6241\n",
            "Epoch 28/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8280 - loss: 0.5648 - val_accuracy: 0.8309 - val_loss: 0.6185\n",
            "Epoch 29/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8298 - loss: 0.5585 - val_accuracy: 0.8364 - val_loss: 0.6128\n",
            "Epoch 30/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8299 - loss: 0.5625 - val_accuracy: 0.8309 - val_loss: 0.6244\n",
            "Epoch 31/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8283 - loss: 0.5571 - val_accuracy: 0.8309 - val_loss: 0.6249\n",
            "Epoch 32/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8306 - loss: 0.5487 - val_accuracy: 0.8271 - val_loss: 0.6226\n",
            "Epoch 33/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8390 - loss: 0.5304 - val_accuracy: 0.8355 - val_loss: 0.6202\n",
            "Epoch 34/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8386 - loss: 0.5370 - val_accuracy: 0.8206 - val_loss: 0.6263\n",
            "Epoch 35/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8364 - loss: 0.5420 - val_accuracy: 0.8262 - val_loss: 0.6156\n",
            "Epoch 36/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8413 - loss: 0.5226 - val_accuracy: 0.8271 - val_loss: 0.6163\n",
            "Epoch 37/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8453 - loss: 0.5084 - val_accuracy: 0.8327 - val_loss: 0.6216\n",
            "Epoch 38/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8435 - loss: 0.5163 - val_accuracy: 0.8336 - val_loss: 0.6277\n",
            "Epoch 39/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8384 - loss: 0.5211 - val_accuracy: 0.8355 - val_loss: 0.6172\n",
            "Epoch 40/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8402 - loss: 0.5094 - val_accuracy: 0.8299 - val_loss: 0.6232\n",
            "Epoch 41/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8434 - loss: 0.5023 - val_accuracy: 0.8271 - val_loss: 0.6282\n",
            "Epoch 42/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8505 - loss: 0.4938 - val_accuracy: 0.8336 - val_loss: 0.6258\n",
            "Epoch 43/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8469 - loss: 0.4971 - val_accuracy: 0.8299 - val_loss: 0.6288\n",
            "Epoch 44/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8539 - loss: 0.4805 - val_accuracy: 0.8374 - val_loss: 0.6257\n",
            "Epoch 45/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8519 - loss: 0.4728 - val_accuracy: 0.8327 - val_loss: 0.6322\n",
            "Epoch 46/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8484 - loss: 0.4744 - val_accuracy: 0.8299 - val_loss: 0.6474\n",
            "Epoch 47/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8511 - loss: 0.4779 - val_accuracy: 0.8299 - val_loss: 0.6440\n",
            "Epoch 48/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8483 - loss: 0.4802 - val_accuracy: 0.8392 - val_loss: 0.6354\n",
            "Epoch 49/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8486 - loss: 0.4750 - val_accuracy: 0.8336 - val_loss: 0.6246\n",
            "Epoch 50/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8537 - loss: 0.4708 - val_accuracy: 0.8309 - val_loss: 0.6303\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x1e0a0cb2f90>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    X_train_avg,\n",
        "    y_train,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val_avg, y_val)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "ee0d0df9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee0d0df9",
        "outputId": "09290229-0f8c-4525-db50-79f6aaee49fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8253 - loss: 0.6472 \n",
            "Test accuracy: 0.8253\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.89      0.92        19\n",
            "           1       0.83      0.91      0.87        11\n",
            "           2       0.71      0.79      0.75        19\n",
            "           3       1.00      0.50      0.67         8\n",
            "           4       0.80      0.80      0.80        15\n",
            "           5       0.68      1.00      0.81        13\n",
            "           6       0.45      0.53      0.49        19\n",
            "           7       1.00      0.89      0.94        19\n",
            "           8       0.81      0.68      0.74        19\n",
            "           9       0.81      0.68      0.74        19\n",
            "          10       0.88      0.88      0.88         8\n",
            "          11       0.83      0.79      0.81        19\n",
            "          12       0.89      1.00      0.94         8\n",
            "          13       0.83      0.79      0.81        19\n",
            "          14       0.75      0.63      0.69        19\n",
            "          15       0.79      0.79      0.79        19\n",
            "          16       0.95      1.00      0.97        19\n",
            "          17       1.00      1.00      1.00        19\n",
            "          18       1.00      1.00      1.00        19\n",
            "          19       1.00      1.00      1.00        19\n",
            "          20       1.00      0.95      0.97        19\n",
            "          21       0.92      0.92      0.92        12\n",
            "          22       0.90      1.00      0.95        19\n",
            "          23       0.95      0.95      0.95        19\n",
            "          24       0.46      0.32      0.38        19\n",
            "          25       0.95      1.00      0.97        19\n",
            "          26       0.94      0.94      0.94        16\n",
            "          27       0.83      1.00      0.90        19\n",
            "          28       0.68      0.68      0.68        19\n",
            "          29       0.77      0.83      0.80        12\n",
            "          30       1.00      0.89      0.94        19\n",
            "          31       0.25      0.67      0.36         3\n",
            "          32       0.70      0.50      0.58        14\n",
            "          33       0.78      0.78      0.78         9\n",
            "          34       0.83      0.71      0.77         7\n",
            "          35       0.84      0.84      0.84        19\n",
            "          36       0.77      0.89      0.83        19\n",
            "          37       0.86      0.95      0.90        19\n",
            "          38       0.88      0.78      0.82        18\n",
            "          39       0.63      0.63      0.63        19\n",
            "          40       0.86      0.86      0.86         7\n",
            "          41       0.82      0.74      0.78        19\n",
            "          42       0.89      0.89      0.89        19\n",
            "          43       0.67      0.74      0.70        19\n",
            "          44       0.64      0.74      0.68        19\n",
            "          45       1.00      0.58      0.73        19\n",
            "          46       0.89      0.84      0.86        19\n",
            "          47       1.00      0.89      0.94        19\n",
            "          48       0.95      0.95      0.95        19\n",
            "          49       0.42      0.53      0.47        19\n",
            "          50       0.81      0.93      0.87        14\n",
            "          51       0.95      1.00      0.97        19\n",
            "          52       0.78      0.74      0.76        19\n",
            "          53       0.93      0.74      0.82        19\n",
            "          54       0.83      1.00      0.91        10\n",
            "          55       1.00      1.00      1.00        19\n",
            "          56       0.76      0.89      0.82        18\n",
            "          57       0.79      0.79      0.79        19\n",
            "          58       0.88      0.79      0.83        19\n",
            "          59       0.67      0.74      0.70        19\n",
            "          60       1.00      1.00      1.00        18\n",
            "          61       0.89      0.89      0.89        19\n",
            "          62       0.95      0.95      0.95        19\n",
            "          63       0.67      0.74      0.70        19\n",
            "\n",
            "    accuracy                           0.83      1076\n",
            "   macro avg       0.83      0.82      0.82      1076\n",
            "weighted avg       0.83      0.83      0.83      1076\n",
            "\n"
          ]
        }
      ],
      "source": [
        "loss, acc = model.evaluate(X_test_avg, y_test)\n",
        "print(f\"Test accuracy: {acc:.4f}\")\n",
        "\n",
        "y_pred = model.predict(X_test_avg)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6eb6327",
      "metadata": {
        "id": "a6eb6327"
      },
      "source": [
        "## 3. Embedding Pre-trained + LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "2619082e",
      "metadata": {
        "id": "2619082e"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "f211b61f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4265, 100)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "7859fe48",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7859fe48",
        "outputId": "b48a6969-39c9-4f5a-fdfa-5546a7fe4cf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.0280 - loss: 3.9252 - val_accuracy: 0.0390 - val_loss: 3.6831\n",
            "Epoch 2/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.0461 - loss: 3.6377 - val_accuracy: 0.0678 - val_loss: 3.5212\n",
            "Epoch 3/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.0634 - loss: 3.4734 - val_accuracy: 0.0716 - val_loss: 3.4097\n",
            "Epoch 4/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.0834 - loss: 3.2781 - val_accuracy: 0.1348 - val_loss: 3.0812\n",
            "Epoch 5/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.1087 - loss: 3.0756 - val_accuracy: 0.1106 - val_loss: 3.1166\n",
            "Epoch 6/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.1256 - loss: 3.0465 - val_accuracy: 0.1533 - val_loss: 2.8414\n",
            "Epoch 7/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.1411 - loss: 2.9044 - val_accuracy: 0.1664 - val_loss: 2.7844\n",
            "Epoch 8/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.1468 - loss: 3.0302 - val_accuracy: 0.1831 - val_loss: 2.8263\n",
            "Epoch 9/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.1691 - loss: 2.8628 - val_accuracy: 0.1822 - val_loss: 2.7292\n",
            "Epoch 10/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.1706 - loss: 2.9029 - val_accuracy: 0.1924 - val_loss: 2.8387\n",
            "Epoch 11/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.1699 - loss: 2.9297 - val_accuracy: 0.1980 - val_loss: 2.7994\n",
            "Epoch 12/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.1890 - loss: 2.7880 - val_accuracy: 0.2286 - val_loss: 2.5988\n",
            "Epoch 13/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.2162 - loss: 2.6658 - val_accuracy: 0.2258 - val_loss: 2.6026\n",
            "Epoch 14/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.2076 - loss: 2.6637 - val_accuracy: 0.2509 - val_loss: 2.4666\n",
            "Epoch 15/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.2432 - loss: 2.5182 - val_accuracy: 0.3002 - val_loss: 2.3620\n",
            "Epoch 16/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.2563 - loss: 2.4397 - val_accuracy: 0.2751 - val_loss: 2.3037\n",
            "Epoch 17/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.2699 - loss: 2.4081 - val_accuracy: 0.3039 - val_loss: 2.2674\n",
            "Epoch 18/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.2834 - loss: 2.4131 - val_accuracy: 0.3411 - val_loss: 2.2010\n",
            "Epoch 19/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.2972 - loss: 2.3397 - val_accuracy: 0.3383 - val_loss: 2.1631\n",
            "Epoch 20/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.3200 - loss: 2.2778 - val_accuracy: 0.3931 - val_loss: 2.0569\n",
            "Epoch 21/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.3354 - loss: 2.2292 - val_accuracy: 0.3745 - val_loss: 2.0258\n",
            "Epoch 22/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.3396 - loss: 2.2001 - val_accuracy: 0.3922 - val_loss: 2.0640\n",
            "Epoch 23/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.3608 - loss: 2.1393 - val_accuracy: 0.3885 - val_loss: 2.0221\n",
            "Epoch 24/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.3738 - loss: 2.0627 - val_accuracy: 0.4182 - val_loss: 1.9099\n",
            "Epoch 25/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.3960 - loss: 1.9856 - val_accuracy: 0.4470 - val_loss: 1.8596\n",
            "Epoch 26/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.4264 - loss: 1.8971 - val_accuracy: 0.4647 - val_loss: 1.8020\n",
            "Epoch 27/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.4243 - loss: 1.9021 - val_accuracy: 0.4610 - val_loss: 1.7914\n",
            "Epoch 28/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.4396 - loss: 1.8683 - val_accuracy: 0.4935 - val_loss: 1.7304\n",
            "Epoch 29/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.3821 - loss: 2.1769 - val_accuracy: 0.4452 - val_loss: 1.9815\n",
            "Epoch 30/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.4139 - loss: 2.0016 - val_accuracy: 0.5093 - val_loss: 1.7564\n",
            "Epoch 31/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.4568 - loss: 1.8731 - val_accuracy: 0.4916 - val_loss: 1.7003\n",
            "Epoch 32/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.4840 - loss: 1.7357 - val_accuracy: 0.5558 - val_loss: 1.5774\n",
            "Epoch 33/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.5020 - loss: 1.6830 - val_accuracy: 0.5548 - val_loss: 1.5588\n",
            "Epoch 34/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.5183 - loss: 1.6183 - val_accuracy: 0.5920 - val_loss: 1.5019\n",
            "Epoch 35/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.5298 - loss: 1.5956 - val_accuracy: 0.5799 - val_loss: 1.4864\n",
            "Epoch 36/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.5512 - loss: 1.5294 - val_accuracy: 0.5976 - val_loss: 1.4313\n",
            "Epoch 37/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.5658 - loss: 1.5000 - val_accuracy: 0.5976 - val_loss: 1.4790\n",
            "Epoch 38/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.5518 - loss: 1.5610 - val_accuracy: 0.5920 - val_loss: 1.4707\n",
            "Epoch 39/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.5562 - loss: 1.5074 - val_accuracy: 0.6199 - val_loss: 1.3768\n",
            "Epoch 40/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.5853 - loss: 1.4179 - val_accuracy: 0.6292 - val_loss: 1.3549\n",
            "Epoch 41/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.5772 - loss: 1.4592 - val_accuracy: 0.6199 - val_loss: 1.3342\n",
            "Epoch 42/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.5820 - loss: 1.4562 - val_accuracy: 0.6199 - val_loss: 1.3791\n",
            "Epoch 43/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.5969 - loss: 1.4068 - val_accuracy: 0.5846 - val_loss: 1.4924\n",
            "Epoch 44/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.5845 - loss: 1.4364 - val_accuracy: 0.6264 - val_loss: 1.3093\n",
            "Epoch 45/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.6148 - loss: 1.3353 - val_accuracy: 0.6413 - val_loss: 1.3070\n",
            "Epoch 46/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.6188 - loss: 1.3251 - val_accuracy: 0.6636 - val_loss: 1.2501\n",
            "Epoch 47/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.6075 - loss: 1.3312 - val_accuracy: 0.6617 - val_loss: 1.3100\n",
            "Epoch 48/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.6279 - loss: 1.2747 - val_accuracy: 0.6636 - val_loss: 1.2494\n",
            "Epoch 49/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.6415 - loss: 1.2249 - val_accuracy: 0.6664 - val_loss: 1.2161\n",
            "Epoch 50/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.6445 - loss: 1.2232 - val_accuracy: 0.6766 - val_loss: 1.1895\n",
            "Restoring model weights from the end of the best epoch: 50.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x1e0ad1e8bd0>"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 1. Tiền xử lý cho mô hình chuỗi\n",
        "# a. Tokenizer: Tạo vocab và chuyển text thành chuỗi chỉ số\n",
        "num_classes = len(le.classes_)\n",
        "\n",
        "all_sentences = df_train['text'].to_list()\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(oov_token=\"<UNK>\")\n",
        "tokenizer.fit_on_texts(all_sentences)\n",
        "train_sequences = tokenizer.texts_to_sequences(all_sentences)\n",
        "test_sequences = tokenizer.texts_to_sequences(df_test['text'].to_list())\n",
        "val_sequences = tokenizer.texts_to_sequences(df_val['text'].to_list())\n",
        "# print(\"Train sequences:\", train_sequences)\n",
        "\n",
        "\n",
        "# b. Padding: Đảm bảo các chuỗi có cùng độ dài\n",
        "max_len = 50\n",
        "X_train_pad = pad_sequences(train_sequences, maxlen=max_len, padding='post')\n",
        "X_test_pad = pad_sequences(test_sequences, maxlen=max_len, padding='post')\n",
        "X_val_pad = pad_sequences(val_sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "\n",
        "# 2. Tạo ma trận trọng số cho Embedding Layer từ Word2Vec\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "embedding_dim = w2v_model.vector_size\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in w2v_model.wv:\n",
        "        embedding_matrix[i] = w2v_model.wv[word]\n",
        "\n",
        "# print(\"Embedding matrix:\", embedding_matrix)\n",
        "\n",
        "\n",
        "# 3. Xây dựng mô hình Sequential với LSTM\n",
        "lstm_model_pretrained = Sequential([\n",
        "    Embedding(\n",
        "        input_dim=vocab_size,\n",
        "        output_dim=embedding_dim,\n",
        "        weights=[embedding_matrix], # Khởi tạo trọng số\n",
        "        trainable=False # Đóng băng lớp Embedding\n",
        "    ),\n",
        "    LSTM(64, dropout=0.2),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "# 4. Compile, huấn luyện (sử earlystopping)\n",
        "lstm_model_pretrained.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',  # Metric to monitor (e.g., validation loss)\n",
        "    min_delta=0.001,     # Minimum change in the monitored metric to qualify as an improvement\n",
        "    patience=50,         # Number of epochs with no improvement after which training will be stopped\n",
        "    verbose=1,           # Verbosity mode (0 for silent, 1 for updates)\n",
        "    mode='min',          # 'min' for metrics that should decrease (like loss), 'max' for metrics that should increase (like accuracy)\n",
        "    restore_best_weights=True # Restores model weights from the epoch with the best value of the monitored metric\n",
        ")\n",
        "\n",
        "lstm_model_pretrained.fit(\n",
        "    X_train_pad,\n",
        "    y_train,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val_pad, y_val),\n",
        "    shuffle=True,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "40d031c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "40d031c7",
        "outputId": "cbcf44ab-6f73-4c38-8290-05bb57834e4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6757 - loss: 1.1718\n",
            "Test accuracy: 0.6757\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.95      0.92        19\n",
            "           1       1.00      0.73      0.84        11\n",
            "           2       0.62      0.79      0.70        19\n",
            "           3       0.00      0.00      0.00         8\n",
            "           4       0.40      0.27      0.32        15\n",
            "           5       0.40      0.77      0.53        13\n",
            "           6       0.38      0.42      0.40        19\n",
            "           7       0.73      0.58      0.65        19\n",
            "           8       0.58      0.37      0.45        19\n",
            "           9       0.77      0.53      0.62        19\n",
            "          10       0.71      0.62      0.67         8\n",
            "          11       0.62      0.79      0.70        19\n",
            "          12       0.71      0.62      0.67         8\n",
            "          13       0.67      0.63      0.65        19\n",
            "          14       0.48      0.53      0.50        19\n",
            "          15       0.67      0.74      0.70        19\n",
            "          16       0.90      1.00      0.95        19\n",
            "          17       0.95      1.00      0.97        19\n",
            "          18       1.00      1.00      1.00        19\n",
            "          19       0.95      0.95      0.95        19\n",
            "          20       0.85      0.89      0.87        19\n",
            "          21       0.86      1.00      0.92        12\n",
            "          22       0.89      0.84      0.86        19\n",
            "          23       0.82      0.95      0.88        19\n",
            "          24       0.27      0.16      0.20        19\n",
            "          25       0.84      0.84      0.84        19\n",
            "          26       0.84      1.00      0.91        16\n",
            "          27       0.89      0.89      0.89        19\n",
            "          28       0.46      0.63      0.53        19\n",
            "          29       0.00      0.00      0.00        12\n",
            "          30       0.61      0.89      0.72        19\n",
            "          31       0.00      0.00      0.00         3\n",
            "          32       0.50      0.43      0.46        14\n",
            "          33       1.00      0.78      0.88         9\n",
            "          34       0.80      0.57      0.67         7\n",
            "          35       0.64      0.74      0.68        19\n",
            "          36       0.78      0.74      0.76        19\n",
            "          37       0.73      0.58      0.65        19\n",
            "          38       0.50      0.17      0.25        18\n",
            "          39       0.41      0.63      0.50        19\n",
            "          40       0.00      0.00      0.00         7\n",
            "          41       0.58      0.74      0.65        19\n",
            "          42       0.94      0.79      0.86        19\n",
            "          43       0.38      0.42      0.40        19\n",
            "          44       0.00      0.00      0.00        19\n",
            "          45       0.41      0.47      0.44        19\n",
            "          46       0.39      0.68      0.50        19\n",
            "          47       1.00      0.84      0.91        19\n",
            "          48       0.69      0.95      0.80        19\n",
            "          49       0.27      0.47      0.35        19\n",
            "          50       0.67      0.71      0.69        14\n",
            "          51       1.00      0.95      0.97        19\n",
            "          52       0.78      0.74      0.76        19\n",
            "          53       0.71      0.63      0.67        19\n",
            "          54       0.50      0.50      0.50        10\n",
            "          55       0.78      0.74      0.76        19\n",
            "          56       0.87      0.72      0.79        18\n",
            "          57       0.74      0.74      0.74        19\n",
            "          58       0.64      0.74      0.68        19\n",
            "          59       0.65      0.58      0.61        19\n",
            "          60       0.85      0.94      0.89        18\n",
            "          61       0.79      0.79      0.79        19\n",
            "          62       0.74      0.89      0.81        19\n",
            "          63       0.47      0.47      0.47        19\n",
            "\n",
            "    accuracy                           0.68      1076\n",
            "   macro avg       0.64      0.65      0.64      1076\n",
            "weighted avg       0.66      0.68      0.66      1076\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\subject\\nlp\\code\\natural_language_processing\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
            "d:\\subject\\nlp\\code\\natural_language_processing\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
            "d:\\subject\\nlp\\code\\natural_language_processing\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        }
      ],
      "source": [
        "loss, acc = lstm_model_pretrained.evaluate(X_test_pad, y_test)\n",
        "\n",
        "print(f\"Test accuracy: {acc:.4f}\")\n",
        "\n",
        "y_pred = lstm_model_pretrained.predict(X_test_pad)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b71e9ba",
      "metadata": {
        "id": "2b71e9ba"
      },
      "source": [
        "## 4. Embedding học từ đầu + LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "f79fb9ab",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0                  what alarms do i have set right now\n",
              "1                      checkout today alarm of meeting\n",
              "2                                report alarm settings\n",
              "3    see see for me the alarms that you have set to...\n",
              "4                         is there an alarm for ten am\n",
              "Name: text, dtype: object"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train['text'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "8688fb76",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8688fb76",
        "outputId": "97214d65-5e5d-4602-80d6-fe35cace4cd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.0163 - loss: 4.1430 - val_accuracy: 0.0177 - val_loss: 4.1278\n",
            "Epoch 2/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.0162 - loss: 4.1360 - val_accuracy: 0.0177 - val_loss: 4.1260\n",
            "Epoch 3/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.0161 - loss: 4.1338 - val_accuracy: 0.0177 - val_loss: 4.1252\n",
            "Epoch 4/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.0168 - loss: 4.1331 - val_accuracy: 0.0177 - val_loss: 4.1249\n",
            "Epoch 5/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.0241 - loss: 4.0843 - val_accuracy: 0.0270 - val_loss: 4.0446\n",
            "Epoch 6/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.0283 - loss: 4.0210 - val_accuracy: 0.0279 - val_loss: 4.0156\n",
            "Epoch 7/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.0271 - loss: 3.9995 - val_accuracy: 0.0279 - val_loss: 3.9878\n",
            "Epoch 8/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.0300 - loss: 3.9863 - val_accuracy: 0.0288 - val_loss: 3.9909\n",
            "Epoch 9/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.0279 - loss: 3.9836 - val_accuracy: 0.0297 - val_loss: 4.0066\n",
            "Epoch 10/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.0283 - loss: 3.9810 - val_accuracy: 0.0297 - val_loss: 4.0009\n",
            "Epoch 11/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.0322 - loss: 3.9347 - val_accuracy: 0.0474 - val_loss: 3.8420\n",
            "Epoch 12/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.0309 - loss: 3.9649 - val_accuracy: 0.0307 - val_loss: 3.9696\n",
            "Epoch 13/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.0288 - loss: 3.9649 - val_accuracy: 0.0316 - val_loss: 3.9646\n",
            "Epoch 14/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.0314 - loss: 3.9639 - val_accuracy: 0.0316 - val_loss: 3.9658\n",
            "Epoch 15/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.0327 - loss: 3.9536 - val_accuracy: 0.0465 - val_loss: 3.8956\n",
            "Epoch 16/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.0442 - loss: 3.7871 - val_accuracy: 0.0455 - val_loss: 3.7163\n",
            "Epoch 17/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.0549 - loss: 3.6186 - val_accuracy: 0.0623 - val_loss: 3.5951\n",
            "Epoch 18/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.0567 - loss: 3.5825 - val_accuracy: 0.0539 - val_loss: 3.6082\n",
            "Epoch 19/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.0749 - loss: 3.4337 - val_accuracy: 0.0901 - val_loss: 3.4317\n",
            "Epoch 20/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.1113 - loss: 3.2407 - val_accuracy: 0.1403 - val_loss: 3.2158\n",
            "Epoch 21/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.1553 - loss: 2.9507 - val_accuracy: 0.1766 - val_loss: 2.9772\n",
            "Epoch 22/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.2018 - loss: 2.7149 - val_accuracy: 0.1933 - val_loss: 2.8255\n",
            "Epoch 23/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.2466 - loss: 2.5186 - val_accuracy: 0.2221 - val_loss: 2.6787\n",
            "Epoch 24/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.3042 - loss: 2.2849 - val_accuracy: 0.3262 - val_loss: 2.4551\n",
            "Epoch 25/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.3815 - loss: 2.0392 - val_accuracy: 0.4015 - val_loss: 2.2453\n",
            "Epoch 26/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.4820 - loss: 1.7934 - val_accuracy: 0.4972 - val_loss: 1.9892\n",
            "Epoch 27/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.5667 - loss: 1.5127 - val_accuracy: 0.4916 - val_loss: 1.8877\n",
            "Epoch 28/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.6210 - loss: 1.3039 - val_accuracy: 0.5743 - val_loss: 1.6576\n",
            "Epoch 29/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.6861 - loss: 1.1117 - val_accuracy: 0.6050 - val_loss: 1.5574\n",
            "Epoch 30/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.7379 - loss: 0.9627 - val_accuracy: 0.6366 - val_loss: 1.4627\n",
            "Epoch 31/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.7742 - loss: 0.8502 - val_accuracy: 0.6812 - val_loss: 1.4168\n",
            "Epoch 32/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.8056 - loss: 0.7432 - val_accuracy: 0.6794 - val_loss: 1.3425\n",
            "Epoch 33/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.8404 - loss: 0.6438 - val_accuracy: 0.7063 - val_loss: 1.3013\n",
            "Epoch 34/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.8593 - loss: 0.5582 - val_accuracy: 0.7147 - val_loss: 1.2617\n",
            "Epoch 35/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.8670 - loss: 0.5124 - val_accuracy: 0.7193 - val_loss: 1.2911\n",
            "Epoch 36/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.8879 - loss: 0.4449 - val_accuracy: 0.7296 - val_loss: 1.2529\n",
            "Epoch 37/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.8941 - loss: 0.4122 - val_accuracy: 0.7416 - val_loss: 1.2002\n",
            "Epoch 38/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.9115 - loss: 0.3648 - val_accuracy: 0.7491 - val_loss: 1.1766\n",
            "Epoch 39/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9174 - loss: 0.3365 - val_accuracy: 0.7491 - val_loss: 1.1859\n",
            "Epoch 40/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.9276 - loss: 0.2944 - val_accuracy: 0.7556 - val_loss: 1.1959\n",
            "Epoch 41/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.9330 - loss: 0.2676 - val_accuracy: 0.7630 - val_loss: 1.1675\n",
            "Epoch 42/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.9371 - loss: 0.2484 - val_accuracy: 0.7454 - val_loss: 1.2346\n",
            "Epoch 43/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.9449 - loss: 0.2322 - val_accuracy: 0.7565 - val_loss: 1.2998\n",
            "Epoch 44/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.9463 - loss: 0.2208 - val_accuracy: 0.7658 - val_loss: 1.2401\n",
            "Epoch 45/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.9534 - loss: 0.1910 - val_accuracy: 0.7816 - val_loss: 1.2003\n",
            "Epoch 46/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.9549 - loss: 0.1848 - val_accuracy: 0.7760 - val_loss: 1.1769\n",
            "Epoch 47/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.9588 - loss: 0.1752 - val_accuracy: 0.7872 - val_loss: 1.1449\n",
            "Epoch 48/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 22ms/step - accuracy: 0.9620 - loss: 0.1606 - val_accuracy: 0.7751 - val_loss: 1.1631\n",
            "Epoch 49/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.9649 - loss: 0.1472 - val_accuracy: 0.7900 - val_loss: 1.2077\n",
            "Epoch 50/50\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - accuracy: 0.9665 - loss: 0.1379 - val_accuracy: 0.7993 - val_loss: 1.1344\n",
            "Restoring model weights from the end of the best epoch: 50.\n"
          ]
        }
      ],
      "source": [
        "num_classes = len(le.classes_)\n",
        "\n",
        "all_sentences = df_train['text'].to_list()\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(oov_token=\"<UNK>\")\n",
        "tokenizer.fit_on_texts(all_sentences)\n",
        "train_sequences = tokenizer.texts_to_sequences(all_sentences)\n",
        "test_sequences = tokenizer.texts_to_sequences(df_test['text'].to_list())\n",
        "val_sequences = tokenizer.texts_to_sequences(df_val['text'].to_list())\n",
        "# print(\"Train sequences:\", train_sequences)\n",
        "\n",
        "\n",
        "# b. Padding: Đảm bảo các chuỗi có cùng độ dài\n",
        "max_len = 50\n",
        "X_train_pad = pad_sequences(train_sequences, maxlen=max_len, padding='post', truncating='post')\n",
        "X_test_pad = pad_sequences(test_sequences, maxlen=max_len, padding='post', truncating='post')\n",
        "X_val_pad = pad_sequences(val_sequences, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "\n",
        "# 2. Tạo ma trận trọng số cho Embedding Layer từ Word2Vec\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "\n",
        "# 4. Xây dựng mô hình\n",
        "lstm_model_scratch = Sequential([\n",
        "    Embedding(\n",
        "        input_dim=vocab_size,\n",
        "        output_dim=100\n",
        "    ),\n",
        "    LSTM(64, dropout=0.2),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "lstm_model_scratch.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=0.001,\n",
        "    patience=50,\n",
        "    verbose=1,\n",
        "    mode='min',\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = lstm_model_scratch.fit(\n",
        "    X_train_pad, y_train,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val_pad, y_val),\n",
        "    shuffle=True,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "ht_BCRy7QiMB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ht_BCRy7QiMB",
        "outputId": "96ec19ca-592c-451b-ed37-f3297935fe1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7686 - loss: 1.2057\n",
            "Test accuracy: 0.7686\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.89      0.92        19\n",
            "           1       0.91      0.91      0.91        11\n",
            "           2       0.71      0.89      0.79        19\n",
            "           3       0.67      0.75      0.71         8\n",
            "           4       0.80      0.80      0.80        15\n",
            "           5       0.69      0.69      0.69        13\n",
            "           6       0.48      0.58      0.52        19\n",
            "           7       0.78      0.95      0.86        19\n",
            "           8       0.61      0.58      0.59        19\n",
            "           9       0.83      0.53      0.65        19\n",
            "          10       0.62      0.62      0.62         8\n",
            "          11       0.64      0.74      0.68        19\n",
            "          12       0.67      1.00      0.80         8\n",
            "          13       0.67      0.95      0.78        19\n",
            "          14       0.45      0.47      0.46        19\n",
            "          15       0.78      0.74      0.76        19\n",
            "          16       0.86      0.95      0.90        19\n",
            "          17       0.95      1.00      0.97        19\n",
            "          18       0.95      1.00      0.97        19\n",
            "          19       0.90      0.95      0.92        19\n",
            "          20       1.00      0.84      0.91        19\n",
            "          21       1.00      0.75      0.86        12\n",
            "          22       0.86      0.95      0.90        19\n",
            "          23       0.83      1.00      0.90        19\n",
            "          24       0.29      0.21      0.24        19\n",
            "          25       0.86      1.00      0.93        19\n",
            "          26       0.94      1.00      0.97        16\n",
            "          27       1.00      0.89      0.94        19\n",
            "          28       0.78      0.74      0.76        19\n",
            "          29       1.00      0.83      0.91        12\n",
            "          30       0.80      0.84      0.82        19\n",
            "          31       0.50      0.67      0.57         3\n",
            "          32       0.90      0.64      0.75        14\n",
            "          33       0.73      0.89      0.80         9\n",
            "          34       1.00      0.86      0.92         7\n",
            "          35       0.94      0.84      0.89        19\n",
            "          36       0.82      0.74      0.78        19\n",
            "          37       0.83      0.79      0.81        19\n",
            "          38       0.77      0.56      0.65        18\n",
            "          39       0.77      0.53      0.62        19\n",
            "          40       0.67      0.86      0.75         7\n",
            "          41       0.65      0.58      0.61        19\n",
            "          42       0.70      0.84      0.76        19\n",
            "          43       0.79      0.58      0.67        19\n",
            "          44       0.69      0.58      0.63        19\n",
            "          45       1.00      0.79      0.88        19\n",
            "          46       0.77      0.89      0.83        19\n",
            "          47       1.00      0.89      0.94        19\n",
            "          48       0.82      0.74      0.78        19\n",
            "          49       0.60      0.32      0.41        19\n",
            "          50       0.75      0.64      0.69        14\n",
            "          51       0.90      0.95      0.92        19\n",
            "          52       0.53      0.84      0.65        19\n",
            "          53       0.48      0.63      0.55        19\n",
            "          54       0.64      0.70      0.67        10\n",
            "          55       0.89      0.84      0.86        19\n",
            "          56       0.64      0.78      0.70        18\n",
            "          57       0.86      0.63      0.73        19\n",
            "          58       0.64      0.74      0.68        19\n",
            "          59       0.60      0.63      0.62        19\n",
            "          60       1.00      1.00      1.00        18\n",
            "          61       0.94      0.84      0.89        19\n",
            "          62       0.86      0.95      0.90        19\n",
            "          63       0.62      0.53      0.57        19\n",
            "\n",
            "    accuracy                           0.77      1076\n",
            "   macro avg       0.77      0.77      0.76      1076\n",
            "weighted avg       0.78      0.77      0.77      1076\n",
            "\n"
          ]
        }
      ],
      "source": [
        "loss, acc = lstm_model_scratch.evaluate(X_test_pad, y_test)\n",
        "\n",
        "print(f\"Test accuracy: {acc:.4f}\")\n",
        "\n",
        "y_pred = lstm_model_scratch.predict(X_test_pad)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0OJLZ5jiONGb",
      "metadata": {
        "id": "0OJLZ5jiONGb"
      },
      "source": [
        "# Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "30ae3d63",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30ae3d63",
        "outputId": "70f22336-4cc2-4d50-c4e2-193e531e8700"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ground true:\n",
            "['reminder_create', 'weather_query', 'flight_search']\n",
            "Logistic Regression:\n",
            "['calendar_set' 'weather_query' 'general_negate']\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Word2vec + Dense:\n",
            "['email_query' 'weather_query' 'email_sendemail']\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "Embedding (Pretrained) + LSTM:\n",
            "['takeaway_query' 'weather_query' 'social_post']\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Embedding (Scratch) + LSTM:\n",
            "['alarm_set' 'alarm_set' 'alarm_set']\n"
          ]
        }
      ],
      "source": [
        "def transform_to_vector(texts, model):\n",
        "    vectors = np.array(\n",
        "        [sentence_to_avg_vector(text, model) for text in texts],\n",
        "        dtype='float32'\n",
        "    )\n",
        "    return vectors\n",
        "\n",
        "texts = [\n",
        "    \"can you remind me to not call my mom\",\n",
        "    \"is it going to be sunny or rainy tomorrow\",\n",
        "    \"find a flight from new york to london but not through paris\"\n",
        "]\n",
        "labels = ['reminder_create', 'weather_query', 'flight_search']\n",
        "\n",
        "print(\"Ground true:\")\n",
        "print(labels)\n",
        "\n",
        "\n",
        "y_pred = tfidf_lr_pipeline.predict(texts)\n",
        "label_pred = le.inverse_transform(y_pred)\n",
        "print(\"Logistic Regression:\")\n",
        "print(label_pred)\n",
        "\n",
        "y_pred = model.predict(transform_to_vector(texts, w2v_model))\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "label_pred = le.inverse_transform(y_pred)\n",
        "print(\"Word2vec + Dense:\")\n",
        "print(label_pred)\n",
        "\n",
        "max_len = max([len(text) for text in texts])\n",
        "text_sequences = tokenizer.texts_to_sequences(texts)\n",
        "texts_pad = pad_sequences(text_sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "y_pred = lstm_model_pretrained.predict(texts_pad)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "label_pred = le.inverse_transform(y_pred)\n",
        "print(\"Embedding (Pretrained) + LSTM:\")\n",
        "print(label_pred)\n",
        "\n",
        "\n",
        "y_pred = lstm_model_scratch.predict(texts_pad)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "label_pred = le.inverse_transform(y_pred)\n",
        "print(\"Embedding (Scratch) + LSTM:\")\n",
        "print(label_pred)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "538326b1",
      "metadata": {
        "id": "538326b1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c2143a8",
      "metadata": {
        "id": "1c2143a8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a64b9db3",
      "metadata": {
        "id": "a64b9db3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Cz_reXJ_Ebox",
      "metadata": {
        "id": "Cz_reXJ_Ebox"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1YPgvAI9Ebox",
      "metadata": {
        "id": "1YPgvAI9Ebox"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
