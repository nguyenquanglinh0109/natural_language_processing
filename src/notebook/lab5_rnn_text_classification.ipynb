{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0da57345",
      "metadata": {
        "id": "0da57345"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e8bda66c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "e8bda66c",
        "outputId": "4b811df0-8fcf-4bd6-9cd1-e469968efddb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (8954, 2)\n",
            "Validation shape: (1076, 2)\n",
            "Test shape: (1076, 2)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 8954,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8954,\n        \"samples\": [\n          \"please show me the list that i have\",\n          \"raise lights to full power\",\n          \"i think you made some mistake, please check it.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 64,\n        \"samples\": [\n          \"recommendation_events\",\n          \"takeaway_query\",\n          \"alarm_query\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_train"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-4c1064f2-a593-475f-b0ff-eebee5728247\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what alarms do i have set right now</td>\n",
              "      <td>alarm_query</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>checkout today alarm of meeting</td>\n",
              "      <td>alarm_query</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>report alarm settings</td>\n",
              "      <td>alarm_query</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>see see for me the alarms that you have set to...</td>\n",
              "      <td>alarm_query</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>is there an alarm for ten am</td>\n",
              "      <td>alarm_query</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c1064f2-a593-475f-b0ff-eebee5728247')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4c1064f2-a593-475f-b0ff-eebee5728247 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4c1064f2-a593-475f-b0ff-eebee5728247');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-851a1446-48cf-40e9-9a48-0632c78ef04b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-851a1446-48cf-40e9-9a48-0632c78ef04b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-851a1446-48cf-40e9-9a48-0632c78ef04b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                text     category\n",
              "0                what alarms do i have set right now  alarm_query\n",
              "1                    checkout today alarm of meeting  alarm_query\n",
              "2                              report alarm settings  alarm_query\n",
              "3  see see for me the alarms that you have set to...  alarm_query\n",
              "4                       is there an alarm for ten am  alarm_query"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "origin_path = r\"\"\n",
        "# Dữ liệu có thể được phân tách bằng tab và không có header\n",
        "df_train = pd.read_csv(os.path.join(origin_path, 'train.csv'), sep=',')\n",
        "df_val = pd.read_csv(os.path.join(origin_path, 'val.csv'), sep=',')\n",
        "df_test = pd.read_csv(os.path.join(origin_path,'test.csv'), sep=',')\n",
        "print(\"Train shape:\", df_train.shape)\n",
        "print(\"Validation shape:\", df_val.shape)\n",
        "print(\"Test shape:\", df_test.shape)\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a28c7da4",
      "metadata": {
        "id": "a28c7da4"
      },
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "le.fit(df_train['category'])\n",
        "df_train['label'] = le.transform(df_train['category'])\n",
        "df_val['label'] = le.transform(df_val['category'])\n",
        "df_test['label'] = le.transform(df_test['category'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7e11a0b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7e11a0b5",
        "outputId": "db4e2337-52fb-4a5d-a70c-2404aa54daea"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 8954,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8954,\n        \"samples\": [\n          \"please show me the list that i have\",\n          \"raise lights to full power\",\n          \"i think you made some mistake, please check it.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 64,\n        \"samples\": [\n          \"recommendation_events\",\n          \"takeaway_query\",\n          \"alarm_query\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18,\n        \"min\": 0,\n        \"max\": 63,\n        \"num_unique_values\": 64,\n        \"samples\": [\n          52,\n          58,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_train"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-80ab2325-0424-4420-a269-2d48a3b8a084\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what alarms do i have set right now</td>\n",
              "      <td>alarm_query</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>checkout today alarm of meeting</td>\n",
              "      <td>alarm_query</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>report alarm settings</td>\n",
              "      <td>alarm_query</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>see see for me the alarms that you have set to...</td>\n",
              "      <td>alarm_query</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>is there an alarm for ten am</td>\n",
              "      <td>alarm_query</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80ab2325-0424-4420-a269-2d48a3b8a084')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-80ab2325-0424-4420-a269-2d48a3b8a084 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-80ab2325-0424-4420-a269-2d48a3b8a084');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e3b4ab36-c8db-40d2-9713-b2dea733f03d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e3b4ab36-c8db-40d2-9713-b2dea733f03d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e3b4ab36-c8db-40d2-9713-b2dea733f03d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                text     category  label\n",
              "0                what alarms do i have set right now  alarm_query      0\n",
              "1                    checkout today alarm of meeting  alarm_query      0\n",
              "2                              report alarm settings  alarm_query      0\n",
              "3  see see for me the alarms that you have set to...  alarm_query      0\n",
              "4                       is there an alarm for ten am  alarm_query      0"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82fa7efc",
      "metadata": {
        "id": "82fa7efc"
      },
      "source": [
        "# TF-IDF + Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "29d15e72",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "29d15e72",
        "outputId": "96e895f7-6f64-4422-e66a-12a8ad1c4562"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.95      0.92        19\n",
            "           1       1.00      0.73      0.84        11\n",
            "           2       0.77      0.89      0.83        19\n",
            "           3       1.00      0.75      0.86         8\n",
            "           4       0.92      0.80      0.86        15\n",
            "           5       0.93      1.00      0.96        13\n",
            "           6       0.45      0.53      0.49        19\n",
            "           7       0.89      0.89      0.89        19\n",
            "           8       0.87      0.68      0.76        19\n",
            "           9       0.59      0.68      0.63        19\n",
            "          10       0.67      0.75      0.71         8\n",
            "          11       0.74      0.89      0.81        19\n",
            "          12       0.78      0.88      0.82         8\n",
            "          13       0.83      0.79      0.81        19\n",
            "          14       0.92      0.63      0.75        19\n",
            "          15       0.81      0.89      0.85        19\n",
            "          16       1.00      1.00      1.00        19\n",
            "          17       1.00      1.00      1.00        19\n",
            "          18       1.00      1.00      1.00        19\n",
            "          19       0.90      1.00      0.95        19\n",
            "          20       1.00      0.95      0.97        19\n",
            "          21       1.00      1.00      1.00        12\n",
            "          22       0.95      1.00      0.97        19\n",
            "          23       0.95      1.00      0.97        19\n",
            "          24       0.36      0.26      0.30        19\n",
            "          25       0.90      1.00      0.95        19\n",
            "          26       1.00      1.00      1.00        16\n",
            "          27       1.00      0.95      0.97        19\n",
            "          28       0.75      0.79      0.77        19\n",
            "          29       0.91      0.83      0.87        12\n",
            "          30       0.89      0.89      0.89        19\n",
            "          31       0.67      0.67      0.67         3\n",
            "          32       1.00      0.86      0.92        14\n",
            "          33       0.80      0.89      0.84         9\n",
            "          34       0.78      1.00      0.88         7\n",
            "          35       0.68      0.79      0.73        19\n",
            "          36       0.75      0.79      0.77        19\n",
            "          37       0.85      0.89      0.87        19\n",
            "          38       0.65      0.61      0.63        18\n",
            "          39       0.71      0.53      0.61        19\n",
            "          40       1.00      0.57      0.73         7\n",
            "          41       0.75      0.63      0.69        19\n",
            "          42       0.95      0.95      0.95        19\n",
            "          43       0.81      0.68      0.74        19\n",
            "          44       0.58      0.74      0.65        19\n",
            "          45       1.00      0.84      0.91        19\n",
            "          46       0.89      0.84      0.86        19\n",
            "          47       0.94      0.89      0.92        19\n",
            "          48       0.82      0.95      0.88        19\n",
            "          49       0.48      0.58      0.52        19\n",
            "          50       0.92      0.86      0.89        14\n",
            "          51       1.00      0.95      0.97        19\n",
            "          52       0.83      0.79      0.81        19\n",
            "          53       0.81      0.89      0.85        19\n",
            "          54       1.00      1.00      1.00        10\n",
            "          55       0.95      1.00      0.97        19\n",
            "          56       0.80      0.89      0.84        18\n",
            "          57       0.83      0.79      0.81        19\n",
            "          58       0.89      0.89      0.89        19\n",
            "          59       0.68      0.79      0.73        19\n",
            "          60       1.00      1.00      1.00        18\n",
            "          61       0.94      0.79      0.86        19\n",
            "          62       1.00      0.95      0.97        19\n",
            "          63       0.62      0.68      0.65        19\n",
            "\n",
            "    accuracy                           0.84      1076\n",
            "   macro avg       0.85      0.83      0.84      1076\n",
            "weighted avg       0.84      0.84      0.84      1076\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "tfidf_lr_pipeline = make_pipeline(\n",
        "    TfidfVectorizer(max_features=5000),\n",
        "    LogisticRegression(max_iter=1000)\n",
        ")\n",
        "\n",
        "tfidf_lr_pipeline.fit(df_train['text'], df_train['label'])\n",
        "y_pred = tfidf_lr_pipeline.predict(df_test['text'])\n",
        "\n",
        "print(classification_report(df_test['label'], y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99c62460",
      "metadata": {
        "id": "99c62460"
      },
      "source": [
        "# Word2Vec + Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "LKzP39P5E99W",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKzP39P5E99W",
        "outputId": "ffc7a318-415c-4bc2-ca6d-d77cc3d7b890"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9b7985ba",
      "metadata": {
        "id": "9b7985ba"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0f2b6fb6",
      "metadata": {
        "id": "0f2b6fb6"
      },
      "outputs": [],
      "source": [
        "# 1. Huấn luyện mô hình Word2Vec trên dữ liệu text của bạn\n",
        "sentences = [text.split() for text in df_train['text']]\n",
        "w2v_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "03c75a06",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03c75a06",
        "outputId": "70c20f73-fe1d-4453-822a-1f01626b5d37"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('tomorrow', 0.996619701385498),\n",
              " ('six', 0.9950720071792603),\n",
              " ('at', 0.9950494766235352),\n",
              " ('eight', 0.9947173595428467),\n",
              " ('am', 0.9946451187133789),\n",
              " ('pm', 0.9944387078285217),\n",
              " ('seven', 0.9938293099403381),\n",
              " ('five', 0.993751585483551),\n",
              " ('morning', 0.9935374855995178),\n",
              " ('set', 0.9933524131774902)]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w2v_model.wv.most_similar(\"alarm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "fd7b8171",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd7b8171",
        "outputId": "11548f0d-bf44-4ec1-94f8-41023122a460"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['alarm_query', 'alarm_remove', 'alarm_set', 'audio_volume_down',\n",
              "       'audio_volume_mute', 'audio_volume_up', 'calendar_query',\n",
              "       'calendar_remove', 'calendar_set', 'cooking_recipe',\n",
              "       'datetime_convert', 'datetime_query', 'email_addcontact',\n",
              "       'email_query', 'email_querycontact', 'email_sendemail',\n",
              "       'general_affirm', 'general_commandstop', 'general_confirm',\n",
              "       'general_dontcare', 'general_explain', 'general_joke',\n",
              "       'general_negate', 'general_praise', 'general_quirky',\n",
              "       'general_repeat', 'iot_cleaning', 'iot_coffee',\n",
              "       'iot_hue_lightchange', 'iot_hue_lightdim', 'iot_hue_lightoff',\n",
              "       'iot_hue_lighton', 'iot_hue_lightup', 'iot_wemo_off',\n",
              "       'iot_wemo_on', 'lists_createoradd', 'lists_query', 'lists_remove',\n",
              "       'music_likeness', 'music_query', 'music_settings', 'news_query',\n",
              "       'play_audiobook', 'play_game', 'play_music', 'play_podcasts',\n",
              "       'play_radio', 'qa_currency', 'qa_definition', 'qa_factoid',\n",
              "       'qa_maths', 'qa_stock', 'recommendation_events',\n",
              "       'recommendation_locations', 'recommendation_movies', 'social_post',\n",
              "       'social_query', 'takeaway_order', 'takeaway_query',\n",
              "       'transport_query', 'transport_taxi', 'transport_ticket',\n",
              "       'transport_traffic', 'weather_query'], dtype=object)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "le.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "bd5b8073",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd5b8073",
        "outputId": "4c4a0daa-b7bd-4d27-daf7-2c498a4ba4f2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "def sentence_to_avg_vector(text, model):\n",
        "    tokens = text.split()\n",
        "    vectors = [model.wv[token] for token in tokens if token in model.wv]\n",
        "\n",
        "    if len(vectors) == 0:\n",
        "        # Trả về vector zero với đúng kích thước embedding\n",
        "        return np.zeros(model.vector_size, dtype='float32')\n",
        "\n",
        "    return np.mean(vectors, axis=0)\n",
        "\n",
        "def transform_to_vector(df, model):\n",
        "    # df = df.sample(frac=1, random_state=42)\n",
        "    texts = df['text'].to_list()\n",
        "    labels = df['label'].to_list()\n",
        "\n",
        "    vectors = np.array(\n",
        "        [sentence_to_avg_vector(text, model) for text in texts],\n",
        "        dtype='float32'\n",
        "    )\n",
        "    return vectors, np.array(labels)\n",
        "\n",
        "# 3. Tạo dữ liệu train/val/test X_train_avg, X_val_avg, X_test_avg\n",
        "X_train_avg, y_train = transform_to_vector(df_train, w2v_model)\n",
        "X_test_avg, y_test = transform_to_vector(df_test, w2v_model)\n",
        "X_val_avg, y_val = transform_to_vector(df_val, w2v_model)\n",
        "\n",
        "# 4. Xây dựng mô hình Sequential của Keras\n",
        "num_classes = len(le.classes_)\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(w2v_model.vector_size,)),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "f956d7c6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f956d7c6",
        "outputId": "c44384e8-34ae-4c27-d5c1-94518dcfe34c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0,  0,  0, ..., 63, 63, 63])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "68250fa8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "68250fa8",
        "outputId": "d55a17ea-fff9-4ac2-81a8-21d079aca766"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.0167 - loss: 4.1658 - val_accuracy: 0.0344 - val_loss: 4.1133\n",
            "Epoch 2/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0336 - loss: 4.1150 - val_accuracy: 0.0558 - val_loss: 4.0694\n",
            "Epoch 3/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0451 - loss: 4.0668 - val_accuracy: 0.0771 - val_loss: 3.9793\n",
            "Epoch 4/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0536 - loss: 3.9746 - val_accuracy: 0.0855 - val_loss: 3.8597\n",
            "Epoch 5/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0677 - loss: 3.8684 - val_accuracy: 0.0809 - val_loss: 3.7469\n",
            "Epoch 6/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0756 - loss: 3.7752 - val_accuracy: 0.1134 - val_loss: 3.6614\n",
            "Epoch 7/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0862 - loss: 3.6924 - val_accuracy: 0.1115 - val_loss: 3.5910\n",
            "Epoch 8/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0974 - loss: 3.6507 - val_accuracy: 0.1580 - val_loss: 3.5365\n",
            "Epoch 9/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1083 - loss: 3.5556 - val_accuracy: 0.1515 - val_loss: 3.4759\n",
            "Epoch 10/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1226 - loss: 3.5134 - val_accuracy: 0.1561 - val_loss: 3.4260\n",
            "Epoch 11/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1231 - loss: 3.4784 - val_accuracy: 0.1710 - val_loss: 3.3984\n",
            "Epoch 12/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1280 - loss: 3.4432 - val_accuracy: 0.1868 - val_loss: 3.3434\n",
            "Epoch 13/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1317 - loss: 3.4118 - val_accuracy: 0.1868 - val_loss: 3.3117\n",
            "Epoch 14/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1383 - loss: 3.3960 - val_accuracy: 0.1942 - val_loss: 3.2885\n",
            "Epoch 15/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1470 - loss: 3.3418 - val_accuracy: 0.1924 - val_loss: 3.2573\n",
            "Epoch 16/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1490 - loss: 3.3425 - val_accuracy: 0.1784 - val_loss: 3.2534\n",
            "Epoch 17/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1579 - loss: 3.3050 - val_accuracy: 0.2110 - val_loss: 3.2007\n",
            "Epoch 18/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1559 - loss: 3.2935 - val_accuracy: 0.2035 - val_loss: 3.2077\n",
            "Epoch 19/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1647 - loss: 3.2627 - val_accuracy: 0.2054 - val_loss: 3.1697\n",
            "Epoch 20/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1613 - loss: 3.2453 - val_accuracy: 0.1924 - val_loss: 3.1691\n",
            "Epoch 21/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1569 - loss: 3.2441 - val_accuracy: 0.2165 - val_loss: 3.1345\n",
            "Epoch 22/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1659 - loss: 3.2329 - val_accuracy: 0.2175 - val_loss: 3.1131\n",
            "Epoch 23/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1692 - loss: 3.1982 - val_accuracy: 0.2212 - val_loss: 3.1049\n",
            "Epoch 24/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1752 - loss: 3.1748 - val_accuracy: 0.2147 - val_loss: 3.0850\n",
            "Epoch 25/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1732 - loss: 3.1739 - val_accuracy: 0.2268 - val_loss: 3.0669\n",
            "Epoch 26/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1772 - loss: 3.1625 - val_accuracy: 0.2277 - val_loss: 3.0498\n",
            "Epoch 27/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1781 - loss: 3.1461 - val_accuracy: 0.2277 - val_loss: 3.0372\n",
            "Epoch 28/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1826 - loss: 3.1495 - val_accuracy: 0.2407 - val_loss: 3.0168\n",
            "Epoch 29/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1877 - loss: 3.1061 - val_accuracy: 0.2314 - val_loss: 3.0075\n",
            "Epoch 30/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1865 - loss: 3.1170 - val_accuracy: 0.2361 - val_loss: 2.9925\n",
            "Epoch 31/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1844 - loss: 3.1028 - val_accuracy: 0.2407 - val_loss: 2.9867\n",
            "Epoch 32/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1944 - loss: 3.0851 - val_accuracy: 0.2546 - val_loss: 2.9688\n",
            "Epoch 33/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1929 - loss: 3.0919 - val_accuracy: 0.2444 - val_loss: 2.9652\n",
            "Epoch 34/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1846 - loss: 3.0858 - val_accuracy: 0.2472 - val_loss: 2.9485\n",
            "Epoch 35/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1988 - loss: 3.0424 - val_accuracy: 0.2481 - val_loss: 2.9490\n",
            "Epoch 36/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2002 - loss: 3.0567 - val_accuracy: 0.2537 - val_loss: 2.9314\n",
            "Epoch 37/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2004 - loss: 3.0538 - val_accuracy: 0.2565 - val_loss: 2.9101\n",
            "Epoch 38/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2049 - loss: 3.0087 - val_accuracy: 0.2584 - val_loss: 2.9038\n",
            "Epoch 39/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2079 - loss: 3.0017 - val_accuracy: 0.2602 - val_loss: 2.9025\n",
            "Epoch 40/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2014 - loss: 3.0323 - val_accuracy: 0.2351 - val_loss: 2.9102\n",
            "Epoch 41/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2077 - loss: 2.9971 - val_accuracy: 0.2658 - val_loss: 2.8775\n",
            "Epoch 42/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2152 - loss: 3.0008 - val_accuracy: 0.2714 - val_loss: 2.8546\n",
            "Epoch 43/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2134 - loss: 2.9845 - val_accuracy: 0.2723 - val_loss: 2.8477\n",
            "Epoch 44/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2168 - loss: 2.9752 - val_accuracy: 0.2686 - val_loss: 2.8530\n",
            "Epoch 45/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2170 - loss: 2.9667 - val_accuracy: 0.2714 - val_loss: 2.8315\n",
            "Epoch 46/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2185 - loss: 2.9507 - val_accuracy: 0.2797 - val_loss: 2.8195\n",
            "Epoch 47/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2219 - loss: 2.9411 - val_accuracy: 0.2816 - val_loss: 2.8291\n",
            "Epoch 48/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2214 - loss: 2.9636 - val_accuracy: 0.2760 - val_loss: 2.8234\n",
            "Epoch 49/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2224 - loss: 2.9363 - val_accuracy: 0.2714 - val_loss: 2.8146\n",
            "Epoch 50/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2215 - loss: 2.9380 - val_accuracy: 0.2909 - val_loss: 2.7867\n",
            "Epoch 51/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2244 - loss: 2.9429 - val_accuracy: 0.2797 - val_loss: 2.7995\n",
            "Epoch 52/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2294 - loss: 2.9189 - val_accuracy: 0.2965 - val_loss: 2.7651\n",
            "Epoch 53/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2278 - loss: 2.8972 - val_accuracy: 0.2760 - val_loss: 2.7832\n",
            "Epoch 54/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2320 - loss: 2.9045 - val_accuracy: 0.2928 - val_loss: 2.7639\n",
            "Epoch 55/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2266 - loss: 2.8972 - val_accuracy: 0.2928 - val_loss: 2.7372\n",
            "Epoch 56/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2413 - loss: 2.8622 - val_accuracy: 0.2974 - val_loss: 2.7514\n",
            "Epoch 57/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2399 - loss: 2.8502 - val_accuracy: 0.3011 - val_loss: 2.7209\n",
            "Epoch 58/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2292 - loss: 2.8799 - val_accuracy: 0.3011 - val_loss: 2.7185\n",
            "Epoch 59/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.2345 - loss: 2.8529 - val_accuracy: 0.2965 - val_loss: 2.7272\n",
            "Epoch 60/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2438 - loss: 2.8672 - val_accuracy: 0.2900 - val_loss: 2.7274\n",
            "Epoch 61/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2313 - loss: 2.8459 - val_accuracy: 0.2983 - val_loss: 2.7017\n",
            "Epoch 62/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2372 - loss: 2.8241 - val_accuracy: 0.2993 - val_loss: 2.6931\n",
            "Epoch 63/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2415 - loss: 2.8231 - val_accuracy: 0.3076 - val_loss: 2.6855\n",
            "Epoch 64/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2395 - loss: 2.8047 - val_accuracy: 0.2974 - val_loss: 2.7016\n",
            "Epoch 65/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2583 - loss: 2.8395 - val_accuracy: 0.2993 - val_loss: 2.6830\n",
            "Epoch 66/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2539 - loss: 2.8167 - val_accuracy: 0.3048 - val_loss: 2.6685\n",
            "Epoch 67/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2477 - loss: 2.8029 - val_accuracy: 0.3197 - val_loss: 2.6702\n",
            "Epoch 68/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2528 - loss: 2.8085 - val_accuracy: 0.3178 - val_loss: 2.6758\n",
            "Epoch 69/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2552 - loss: 2.7843 - val_accuracy: 0.3058 - val_loss: 2.6704\n",
            "Epoch 70/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2587 - loss: 2.7888 - val_accuracy: 0.3076 - val_loss: 2.6451\n",
            "Epoch 71/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2512 - loss: 2.7838 - val_accuracy: 0.3123 - val_loss: 2.6400\n",
            "Epoch 72/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2490 - loss: 2.7664 - val_accuracy: 0.3058 - val_loss: 2.6415\n",
            "Epoch 73/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2519 - loss: 2.7657 - val_accuracy: 0.3197 - val_loss: 2.6270\n",
            "Epoch 74/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2614 - loss: 2.7829 - val_accuracy: 0.3160 - val_loss: 2.6317\n",
            "Epoch 75/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2570 - loss: 2.7733 - val_accuracy: 0.3058 - val_loss: 2.6359\n",
            "Epoch 76/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2463 - loss: 2.7745 - val_accuracy: 0.3216 - val_loss: 2.6069\n",
            "Epoch 77/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2683 - loss: 2.7594 - val_accuracy: 0.3197 - val_loss: 2.6048\n",
            "Epoch 78/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2589 - loss: 2.7167 - val_accuracy: 0.3123 - val_loss: 2.6220\n",
            "Epoch 79/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2666 - loss: 2.7071 - val_accuracy: 0.3132 - val_loss: 2.6016\n",
            "Epoch 80/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2610 - loss: 2.7725 - val_accuracy: 0.3253 - val_loss: 2.5844\n",
            "Epoch 81/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2618 - loss: 2.7453 - val_accuracy: 0.3113 - val_loss: 2.5904\n",
            "Epoch 82/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2662 - loss: 2.7160 - val_accuracy: 0.3299 - val_loss: 2.5697\n",
            "Epoch 83/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2708 - loss: 2.6951 - val_accuracy: 0.3401 - val_loss: 2.5637\n",
            "Epoch 84/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.2655 - loss: 2.7100 - val_accuracy: 0.3318 - val_loss: 2.5809\n",
            "Epoch 85/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2761 - loss: 2.7011 - val_accuracy: 0.3290 - val_loss: 2.5654\n",
            "Epoch 86/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2686 - loss: 2.6997 - val_accuracy: 0.3281 - val_loss: 2.5618\n",
            "Epoch 87/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2768 - loss: 2.7019 - val_accuracy: 0.3346 - val_loss: 2.5364\n",
            "Epoch 88/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2866 - loss: 2.6682 - val_accuracy: 0.3262 - val_loss: 2.5482\n",
            "Epoch 89/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2685 - loss: 2.6718 - val_accuracy: 0.3281 - val_loss: 2.5438\n",
            "Epoch 90/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2775 - loss: 2.6834 - val_accuracy: 0.3188 - val_loss: 2.5415\n",
            "Epoch 91/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2764 - loss: 2.6669 - val_accuracy: 0.3420 - val_loss: 2.5321\n",
            "Epoch 92/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2810 - loss: 2.6889 - val_accuracy: 0.3383 - val_loss: 2.5315\n",
            "Epoch 93/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2738 - loss: 2.6791 - val_accuracy: 0.3234 - val_loss: 2.5469\n",
            "Epoch 94/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2890 - loss: 2.6433 - val_accuracy: 0.3439 - val_loss: 2.5066\n",
            "Epoch 95/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2841 - loss: 2.6314 - val_accuracy: 0.3401 - val_loss: 2.5064\n",
            "Epoch 96/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2829 - loss: 2.6382 - val_accuracy: 0.3476 - val_loss: 2.5069\n",
            "Epoch 97/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2892 - loss: 2.6677 - val_accuracy: 0.3439 - val_loss: 2.5104\n",
            "Epoch 98/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2825 - loss: 2.6648 - val_accuracy: 0.3532 - val_loss: 2.4903\n",
            "Epoch 99/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2770 - loss: 2.6323 - val_accuracy: 0.3476 - val_loss: 2.5010\n",
            "Epoch 100/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2929 - loss: 2.6420 - val_accuracy: 0.3439 - val_loss: 2.4794\n",
            "Epoch 101/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2898 - loss: 2.6233 - val_accuracy: 0.3364 - val_loss: 2.4856\n",
            "Epoch 102/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2805 - loss: 2.6578 - val_accuracy: 0.3309 - val_loss: 2.4840\n",
            "Epoch 103/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2895 - loss: 2.6153 - val_accuracy: 0.3541 - val_loss: 2.4738\n",
            "Epoch 104/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2904 - loss: 2.6200 - val_accuracy: 0.3522 - val_loss: 2.4646\n",
            "Epoch 105/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2833 - loss: 2.6165 - val_accuracy: 0.3467 - val_loss: 2.4606\n",
            "Epoch 106/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2963 - loss: 2.6246 - val_accuracy: 0.3476 - val_loss: 2.4694\n",
            "Epoch 107/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2940 - loss: 2.6346 - val_accuracy: 0.3559 - val_loss: 2.4527\n",
            "Epoch 108/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2849 - loss: 2.6261 - val_accuracy: 0.3448 - val_loss: 2.4495\n",
            "Epoch 109/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2968 - loss: 2.5989 - val_accuracy: 0.3504 - val_loss: 2.4474\n",
            "Epoch 110/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2946 - loss: 2.6164 - val_accuracy: 0.3532 - val_loss: 2.4416\n",
            "Epoch 111/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2950 - loss: 2.5855 - val_accuracy: 0.3411 - val_loss: 2.4447\n",
            "Epoch 112/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2990 - loss: 2.5891 - val_accuracy: 0.3485 - val_loss: 2.4447\n",
            "Epoch 113/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2980 - loss: 2.5956 - val_accuracy: 0.3494 - val_loss: 2.4292\n",
            "Epoch 114/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3069 - loss: 2.5666 - val_accuracy: 0.3392 - val_loss: 2.4671\n",
            "Epoch 115/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2980 - loss: 2.5736 - val_accuracy: 0.3625 - val_loss: 2.4244\n",
            "Epoch 116/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3018 - loss: 2.6144 - val_accuracy: 0.3550 - val_loss: 2.4526\n",
            "Epoch 117/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2932 - loss: 2.5933 - val_accuracy: 0.3494 - val_loss: 2.4312\n",
            "Epoch 118/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2997 - loss: 2.5793 - val_accuracy: 0.3745 - val_loss: 2.4063\n",
            "Epoch 119/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2988 - loss: 2.5567 - val_accuracy: 0.3457 - val_loss: 2.4182\n",
            "Epoch 120/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2959 - loss: 2.5789 - val_accuracy: 0.3597 - val_loss: 2.4136\n",
            "Epoch 121/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2948 - loss: 2.5842 - val_accuracy: 0.3467 - val_loss: 2.4308\n",
            "Epoch 122/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3017 - loss: 2.5624 - val_accuracy: 0.3671 - val_loss: 2.4037\n",
            "Epoch 123/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3167 - loss: 2.5720 - val_accuracy: 0.3615 - val_loss: 2.3942\n",
            "Epoch 124/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3075 - loss: 2.5611 - val_accuracy: 0.3801 - val_loss: 2.3948\n",
            "Epoch 125/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3118 - loss: 2.5377 - val_accuracy: 0.3699 - val_loss: 2.3873\n",
            "Epoch 126/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3106 - loss: 2.5428 - val_accuracy: 0.3736 - val_loss: 2.3969\n",
            "Epoch 127/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3124 - loss: 2.5543 - val_accuracy: 0.3745 - val_loss: 2.3964\n",
            "Epoch 128/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3117 - loss: 2.5596 - val_accuracy: 0.3569 - val_loss: 2.3752\n",
            "Epoch 129/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3187 - loss: 2.5236 - val_accuracy: 0.3680 - val_loss: 2.4049\n",
            "Epoch 130/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3006 - loss: 2.5215 - val_accuracy: 0.3736 - val_loss: 2.3881\n",
            "Epoch 131/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3113 - loss: 2.5241 - val_accuracy: 0.3652 - val_loss: 2.3893\n",
            "Epoch 132/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3117 - loss: 2.5422 - val_accuracy: 0.3671 - val_loss: 2.3717\n",
            "Epoch 133/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3123 - loss: 2.5252 - val_accuracy: 0.3764 - val_loss: 2.3807\n",
            "Epoch 134/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3123 - loss: 2.5371 - val_accuracy: 0.3643 - val_loss: 2.3821\n",
            "Epoch 135/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3185 - loss: 2.5042 - val_accuracy: 0.3773 - val_loss: 2.3666\n",
            "Epoch 136/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3091 - loss: 2.5209 - val_accuracy: 0.3662 - val_loss: 2.3970\n",
            "Epoch 137/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3189 - loss: 2.4834 - val_accuracy: 0.3866 - val_loss: 2.3707\n",
            "Epoch 138/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3306 - loss: 2.4844 - val_accuracy: 0.3736 - val_loss: 2.3626\n",
            "Epoch 139/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3113 - loss: 2.5063 - val_accuracy: 0.3708 - val_loss: 2.3549\n",
            "Epoch 140/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3175 - loss: 2.5058 - val_accuracy: 0.3699 - val_loss: 2.3688\n",
            "Epoch 141/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3158 - loss: 2.5090 - val_accuracy: 0.3513 - val_loss: 2.3618\n",
            "Epoch 142/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3170 - loss: 2.4937 - val_accuracy: 0.3736 - val_loss: 2.3380\n",
            "Epoch 143/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3206 - loss: 2.4965 - val_accuracy: 0.3745 - val_loss: 2.3489\n",
            "Epoch 144/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3198 - loss: 2.4959 - val_accuracy: 0.3913 - val_loss: 2.3167\n",
            "Epoch 145/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3313 - loss: 2.4619 - val_accuracy: 0.3708 - val_loss: 2.3326\n",
            "Epoch 146/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3205 - loss: 2.4938 - val_accuracy: 0.3755 - val_loss: 2.3246\n",
            "Epoch 147/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3350 - loss: 2.4718 - val_accuracy: 0.3801 - val_loss: 2.3330\n",
            "Epoch 148/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3215 - loss: 2.4564 - val_accuracy: 0.3810 - val_loss: 2.3255\n",
            "Epoch 149/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3295 - loss: 2.4661 - val_accuracy: 0.3996 - val_loss: 2.3176\n",
            "Epoch 150/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3234 - loss: 2.4655 - val_accuracy: 0.3820 - val_loss: 2.3148\n",
            "Epoch 151/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3226 - loss: 2.4787 - val_accuracy: 0.3801 - val_loss: 2.3307\n",
            "Epoch 152/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3208 - loss: 2.4635 - val_accuracy: 0.3894 - val_loss: 2.3253\n",
            "Epoch 153/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3235 - loss: 2.4890 - val_accuracy: 0.3903 - val_loss: 2.3255\n",
            "Epoch 154/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3249 - loss: 2.5027 - val_accuracy: 0.3773 - val_loss: 2.3252\n",
            "Epoch 155/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3160 - loss: 2.4821 - val_accuracy: 0.3885 - val_loss: 2.3035\n",
            "Epoch 156/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3137 - loss: 2.4955 - val_accuracy: 0.3950 - val_loss: 2.3048\n",
            "Epoch 157/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3210 - loss: 2.4443 - val_accuracy: 0.3857 - val_loss: 2.3014\n",
            "Epoch 158/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3392 - loss: 2.4229 - val_accuracy: 0.3959 - val_loss: 2.2918\n",
            "Epoch 159/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3295 - loss: 2.4505 - val_accuracy: 0.3773 - val_loss: 2.3051\n",
            "Epoch 160/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3288 - loss: 2.4491 - val_accuracy: 0.3875 - val_loss: 2.2841\n",
            "Epoch 161/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3243 - loss: 2.4549 - val_accuracy: 0.3913 - val_loss: 2.2967\n",
            "Epoch 162/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3215 - loss: 2.4541 - val_accuracy: 0.4006 - val_loss: 2.2761\n",
            "Epoch 163/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3401 - loss: 2.4241 - val_accuracy: 0.3903 - val_loss: 2.2810\n",
            "Epoch 164/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3359 - loss: 2.4153 - val_accuracy: 0.3894 - val_loss: 2.2744\n",
            "Epoch 165/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3397 - loss: 2.4173 - val_accuracy: 0.3968 - val_loss: 2.2843\n",
            "Epoch 166/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3412 - loss: 2.4173 - val_accuracy: 0.3931 - val_loss: 2.2685\n",
            "Epoch 167/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3241 - loss: 2.4756 - val_accuracy: 0.4043 - val_loss: 2.2730\n",
            "Epoch 168/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3424 - loss: 2.4317 - val_accuracy: 0.3913 - val_loss: 2.2852\n",
            "Epoch 169/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3332 - loss: 2.4597 - val_accuracy: 0.4043 - val_loss: 2.2795\n",
            "Epoch 170/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3302 - loss: 2.4610 - val_accuracy: 0.4136 - val_loss: 2.2583\n",
            "Epoch 171/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3532 - loss: 2.3860 - val_accuracy: 0.3875 - val_loss: 2.2603\n",
            "Epoch 172/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3427 - loss: 2.4205 - val_accuracy: 0.4033 - val_loss: 2.2715\n",
            "Epoch 173/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3430 - loss: 2.3871 - val_accuracy: 0.4043 - val_loss: 2.2572\n",
            "Epoch 174/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3346 - loss: 2.3921 - val_accuracy: 0.4033 - val_loss: 2.2376\n",
            "Epoch 175/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3439 - loss: 2.3875 - val_accuracy: 0.4080 - val_loss: 2.2443\n",
            "Epoch 176/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3331 - loss: 2.4183 - val_accuracy: 0.4145 - val_loss: 2.2484\n",
            "Epoch 177/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3419 - loss: 2.3940 - val_accuracy: 0.4210 - val_loss: 2.2375\n",
            "Epoch 178/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3462 - loss: 2.4122 - val_accuracy: 0.4061 - val_loss: 2.2559\n",
            "Epoch 179/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3465 - loss: 2.3823 - val_accuracy: 0.4033 - val_loss: 2.2349\n",
            "Epoch 180/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3476 - loss: 2.3807 - val_accuracy: 0.4154 - val_loss: 2.2280\n",
            "Epoch 181/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3420 - loss: 2.3943 - val_accuracy: 0.3903 - val_loss: 2.2653\n",
            "Epoch 182/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3466 - loss: 2.3776 - val_accuracy: 0.4117 - val_loss: 2.2356\n",
            "Epoch 183/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3434 - loss: 2.3946 - val_accuracy: 0.4191 - val_loss: 2.2438\n",
            "Epoch 184/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.3460 - loss: 2.4140 - val_accuracy: 0.4024 - val_loss: 2.2338\n",
            "Epoch 185/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3507 - loss: 2.3370 - val_accuracy: 0.4164 - val_loss: 2.2325\n",
            "Epoch 186/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3430 - loss: 2.3826 - val_accuracy: 0.4071 - val_loss: 2.2228\n",
            "Epoch 187/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3463 - loss: 2.4007 - val_accuracy: 0.4145 - val_loss: 2.2118\n",
            "Epoch 188/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3459 - loss: 2.3748 - val_accuracy: 0.4145 - val_loss: 2.2177\n",
            "Epoch 189/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3423 - loss: 2.4115 - val_accuracy: 0.4015 - val_loss: 2.2459\n",
            "Epoch 190/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3497 - loss: 2.3654 - val_accuracy: 0.3959 - val_loss: 2.2334\n",
            "Epoch 191/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3517 - loss: 2.3810 - val_accuracy: 0.4061 - val_loss: 2.2088\n",
            "Epoch 192/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3503 - loss: 2.3661 - val_accuracy: 0.4191 - val_loss: 2.2109\n",
            "Epoch 193/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3538 - loss: 2.3405 - val_accuracy: 0.4108 - val_loss: 2.2264\n",
            "Epoch 194/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3408 - loss: 2.3566 - val_accuracy: 0.4089 - val_loss: 2.2140\n",
            "Epoch 195/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3457 - loss: 2.3785 - val_accuracy: 0.4182 - val_loss: 2.1976\n",
            "Epoch 196/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3567 - loss: 2.3615 - val_accuracy: 0.4145 - val_loss: 2.2134\n",
            "Epoch 197/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3468 - loss: 2.3863 - val_accuracy: 0.4071 - val_loss: 2.1861\n",
            "Epoch 198/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3509 - loss: 2.3510 - val_accuracy: 0.4089 - val_loss: 2.2182\n",
            "Epoch 199/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3533 - loss: 2.3402 - val_accuracy: 0.4145 - val_loss: 2.2161\n",
            "Epoch 200/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3585 - loss: 2.3724 - val_accuracy: 0.4257 - val_loss: 2.1871\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7eef7e13f980>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    X_train_avg,\n",
        "    y_train,\n",
        "    epochs=200,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val_avg, y_val)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "ee0d0df9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee0d0df9",
        "outputId": "09290229-0f8c-4525-db50-79f6aaee49fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4555 - loss: 2.0383\n",
            "Test accuracy: 0.4126\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.58      0.49        19\n",
            "           1       0.60      0.27      0.38        11\n",
            "           2       0.57      0.89      0.69        19\n",
            "           3       0.60      0.38      0.46         8\n",
            "           4       0.29      0.13      0.18        15\n",
            "           5       0.86      0.46      0.60        13\n",
            "           6       0.11      0.05      0.07        19\n",
            "           7       0.33      0.53      0.41        19\n",
            "           8       0.19      0.26      0.22        19\n",
            "           9       0.15      0.16      0.15        19\n",
            "          10       0.00      0.00      0.00         8\n",
            "          11       0.46      0.63      0.53        19\n",
            "          12       0.50      0.62      0.56         8\n",
            "          13       0.29      0.42      0.34        19\n",
            "          14       0.25      0.05      0.09        19\n",
            "          15       0.45      0.68      0.54        19\n",
            "          16       0.57      0.63      0.60        19\n",
            "          17       0.83      1.00      0.90        19\n",
            "          18       1.00      0.89      0.94        19\n",
            "          19       0.37      0.53      0.43        19\n",
            "          20       0.34      0.53      0.42        19\n",
            "          21       0.40      0.17      0.24        12\n",
            "          22       0.53      0.53      0.53        19\n",
            "          23       0.61      0.74      0.67        19\n",
            "          24       0.00      0.00      0.00        19\n",
            "          25       0.60      0.63      0.62        19\n",
            "          26       0.86      0.75      0.80        16\n",
            "          27       0.74      0.74      0.74        19\n",
            "          28       0.70      0.84      0.76        19\n",
            "          29       0.33      0.25      0.29        12\n",
            "          30       0.68      0.79      0.73        19\n",
            "          31       0.00      0.00      0.00         3\n",
            "          32       0.30      0.21      0.25        14\n",
            "          33       0.55      0.67      0.60         9\n",
            "          34       0.38      0.71      0.50         7\n",
            "          35       0.50      0.63      0.56        19\n",
            "          36       0.58      0.37      0.45        19\n",
            "          37       0.50      0.53      0.51        19\n",
            "          38       0.29      0.44      0.35        18\n",
            "          39       0.21      0.32      0.26        19\n",
            "          40       0.00      0.00      0.00         7\n",
            "          41       0.08      0.11      0.09        19\n",
            "          42       0.18      0.11      0.13        19\n",
            "          43       0.30      0.37      0.33        19\n",
            "          44       0.40      0.32      0.35        19\n",
            "          45       0.42      0.42      0.42        19\n",
            "          46       0.38      0.42      0.40        19\n",
            "          47       0.43      0.53      0.48        19\n",
            "          48       0.25      0.11      0.15        19\n",
            "          49       0.19      0.21      0.20        19\n",
            "          50       0.35      0.43      0.39        14\n",
            "          51       0.32      0.47      0.38        19\n",
            "          52       0.31      0.47      0.38        19\n",
            "          53       0.00      0.00      0.00        19\n",
            "          54       0.00      0.00      0.00        10\n",
            "          55       0.13      0.11      0.12        19\n",
            "          56       0.25      0.11      0.15        18\n",
            "          57       0.23      0.47      0.31        19\n",
            "          58       0.09      0.05      0.07        19\n",
            "          59       0.35      0.32      0.33        19\n",
            "          60       0.44      0.44      0.44        18\n",
            "          61       0.56      0.74      0.64        19\n",
            "          62       0.40      0.21      0.28        19\n",
            "          63       0.25      0.11      0.15        19\n",
            "\n",
            "    accuracy                           0.41      1076\n",
            "   macro avg       0.38      0.40      0.38      1076\n",
            "weighted avg       0.39      0.41      0.39      1076\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "loss, acc = model.evaluate(X_test_avg, y_test)\n",
        "print(f\"Test accuracy: {acc:.4f}\")\n",
        "\n",
        "y_pred = model.predict(X_test_avg)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6eb6327",
      "metadata": {
        "id": "a6eb6327"
      },
      "source": [
        "## 3. Embedding Pre-trained + LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "2619082e",
      "metadata": {
        "id": "2619082e"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "7859fe48",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7859fe48",
        "outputId": "b48a6969-39c9-4f5a-fdfa-5546a7fe4cf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.0161 - loss: 4.1498 - val_accuracy: 0.0242 - val_loss: 4.1136\n",
            "Epoch 2/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0282 - loss: 4.0642 - val_accuracy: 0.0455 - val_loss: 3.9111\n",
            "Epoch 3/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0445 - loss: 3.9196 - val_accuracy: 0.0660 - val_loss: 3.7704\n",
            "Epoch 4/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0495 - loss: 3.8314 - val_accuracy: 0.0623 - val_loss: 3.7439\n",
            "Epoch 5/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.0599 - loss: 3.7887 - val_accuracy: 0.0771 - val_loss: 3.6909\n",
            "Epoch 6/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.0671 - loss: 3.7252 - val_accuracy: 0.0911 - val_loss: 3.5703\n",
            "Epoch 7/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0705 - loss: 3.6517 - val_accuracy: 0.0939 - val_loss: 3.5104\n",
            "Epoch 8/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0779 - loss: 3.6029 - val_accuracy: 0.0874 - val_loss: 3.5481\n",
            "Epoch 9/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0869 - loss: 3.5696 - val_accuracy: 0.1097 - val_loss: 3.4370\n",
            "Epoch 10/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.0897 - loss: 3.5307 - val_accuracy: 0.0372 - val_loss: 4.1600\n",
            "Epoch 11/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0540 - loss: 3.8956 - val_accuracy: 0.0688 - val_loss: 3.7546\n",
            "Epoch 12/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0560 - loss: 3.8684 - val_accuracy: 0.0623 - val_loss: 3.6925\n",
            "Epoch 13/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0556 - loss: 3.7878 - val_accuracy: 0.0855 - val_loss: 3.5755\n",
            "Epoch 14/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0682 - loss: 3.6568 - val_accuracy: 0.0920 - val_loss: 3.5403\n",
            "Epoch 15/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0504 - loss: 3.9115 - val_accuracy: 0.0428 - val_loss: 3.8472\n",
            "Epoch 16/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.0550 - loss: 3.8234 - val_accuracy: 0.0743 - val_loss: 3.6436\n",
            "Epoch 17/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0657 - loss: 3.6718 - val_accuracy: 0.0901 - val_loss: 3.6391\n",
            "Epoch 18/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0786 - loss: 3.5938 - val_accuracy: 0.0985 - val_loss: 3.4592\n",
            "Epoch 19/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0865 - loss: 3.5247 - val_accuracy: 0.1125 - val_loss: 3.4157\n",
            "Epoch 20/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0996 - loss: 3.4464 - val_accuracy: 0.1366 - val_loss: 3.3159\n",
            "Epoch 21/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1196 - loss: 3.3842 - val_accuracy: 0.1255 - val_loss: 3.3508\n",
            "Epoch 22/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.1126 - loss: 3.3631 - val_accuracy: 0.1227 - val_loss: 3.2764\n",
            "Epoch 23/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1035 - loss: 3.3865 - val_accuracy: 0.1375 - val_loss: 3.2465\n",
            "Epoch 24/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1231 - loss: 3.3353 - val_accuracy: 0.1366 - val_loss: 3.2653\n",
            "Epoch 25/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1233 - loss: 3.3102 - val_accuracy: 0.1441 - val_loss: 3.1872\n",
            "Epoch 26/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1263 - loss: 3.3102 - val_accuracy: 0.1403 - val_loss: 3.1921\n",
            "Epoch 27/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1282 - loss: 3.2881 - val_accuracy: 0.1636 - val_loss: 3.1239\n",
            "Epoch 28/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.1294 - loss: 3.2869 - val_accuracy: 0.1459 - val_loss: 3.2101\n",
            "Epoch 29/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1312 - loss: 3.2714 - val_accuracy: 0.1552 - val_loss: 3.1285\n",
            "Epoch 30/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.1404 - loss: 3.2103 - val_accuracy: 0.1552 - val_loss: 3.1903\n",
            "Epoch 31/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.1441 - loss: 3.2118 - val_accuracy: 0.1608 - val_loss: 3.0918\n",
            "Epoch 32/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.1436 - loss: 3.2203 - val_accuracy: 0.1496 - val_loss: 3.1158\n",
            "Epoch 33/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.1399 - loss: 3.2242 - val_accuracy: 0.1719 - val_loss: 3.0497\n",
            "Epoch 34/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.1510 - loss: 3.1671 - val_accuracy: 0.1682 - val_loss: 3.1257\n",
            "Epoch 35/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1474 - loss: 3.1750 - val_accuracy: 0.1645 - val_loss: 3.0717\n",
            "Epoch 36/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1478 - loss: 3.1584 - val_accuracy: 0.1673 - val_loss: 3.0731\n",
            "Epoch 37/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1536 - loss: 3.1443 - val_accuracy: 0.1710 - val_loss: 3.0185\n",
            "Epoch 38/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.1605 - loss: 3.1185 - val_accuracy: 0.1896 - val_loss: 2.9993\n",
            "Epoch 39/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1544 - loss: 3.0938 - val_accuracy: 0.1506 - val_loss: 3.0707\n",
            "Epoch 40/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1624 - loss: 3.0923 - val_accuracy: 0.1896 - val_loss: 3.0101\n",
            "Epoch 41/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1816 - loss: 3.0434 - val_accuracy: 0.1859 - val_loss: 2.9910\n",
            "Epoch 42/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1914 - loss: 2.9883 - val_accuracy: 0.2193 - val_loss: 2.8668\n",
            "Epoch 43/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1938 - loss: 2.9872 - val_accuracy: 0.2184 - val_loss: 2.8763\n",
            "Epoch 44/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.1995 - loss: 2.9684 - val_accuracy: 0.2063 - val_loss: 2.8822\n",
            "Epoch 45/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.2046 - loss: 2.9402 - val_accuracy: 0.2249 - val_loss: 2.8201\n",
            "Epoch 46/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.2104 - loss: 2.9012 - val_accuracy: 0.2305 - val_loss: 2.7954\n",
            "Epoch 47/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.2223 - loss: 2.8831 - val_accuracy: 0.2472 - val_loss: 2.7272\n",
            "Epoch 48/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.2038 - loss: 2.9557 - val_accuracy: 0.2203 - val_loss: 2.8033\n",
            "Epoch 49/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.2252 - loss: 2.8307 - val_accuracy: 0.2519 - val_loss: 2.7347\n",
            "Epoch 50/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.2241 - loss: 2.8110 - val_accuracy: 0.2732 - val_loss: 2.7011\n",
            "Epoch 51/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.2441 - loss: 2.7689 - val_accuracy: 0.2593 - val_loss: 2.6646\n",
            "Epoch 52/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.2421 - loss: 2.7780 - val_accuracy: 0.2602 - val_loss: 2.7062\n",
            "Epoch 53/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.2488 - loss: 2.7519 - val_accuracy: 0.2751 - val_loss: 2.6277\n",
            "Epoch 54/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.2543 - loss: 2.7135 - val_accuracy: 0.2900 - val_loss: 2.5842\n",
            "Epoch 55/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.2582 - loss: 2.6945 - val_accuracy: 0.2723 - val_loss: 2.6246\n",
            "Epoch 56/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.2671 - loss: 2.6803 - val_accuracy: 0.2732 - val_loss: 2.5744\n",
            "Epoch 57/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.2674 - loss: 2.6677 - val_accuracy: 0.2993 - val_loss: 2.5510\n",
            "Epoch 58/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.2762 - loss: 2.6286 - val_accuracy: 0.2946 - val_loss: 2.5541\n",
            "Epoch 59/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.2868 - loss: 2.6054 - val_accuracy: 0.3206 - val_loss: 2.4758\n",
            "Epoch 60/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.2882 - loss: 2.5896 - val_accuracy: 0.2965 - val_loss: 2.5374\n",
            "Epoch 61/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.2959 - loss: 2.5759 - val_accuracy: 0.3123 - val_loss: 2.4784\n",
            "Epoch 62/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.3007 - loss: 2.5377 - val_accuracy: 0.3299 - val_loss: 2.4906\n",
            "Epoch 63/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3108 - loss: 2.5066 - val_accuracy: 0.3206 - val_loss: 2.4563\n",
            "Epoch 64/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3099 - loss: 2.5038 - val_accuracy: 0.3309 - val_loss: 2.4265\n",
            "Epoch 65/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3203 - loss: 2.4672 - val_accuracy: 0.3327 - val_loss: 2.4105\n",
            "Epoch 66/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3185 - loss: 2.4659 - val_accuracy: 0.3411 - val_loss: 2.3802\n",
            "Epoch 67/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3248 - loss: 2.4634 - val_accuracy: 0.3467 - val_loss: 2.3765\n",
            "Epoch 68/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3201 - loss: 2.4208 - val_accuracy: 0.3494 - val_loss: 2.3640\n",
            "Epoch 69/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3347 - loss: 2.4061 - val_accuracy: 0.3383 - val_loss: 2.3571\n",
            "Epoch 70/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.3297 - loss: 2.4199 - val_accuracy: 0.3206 - val_loss: 2.4162\n",
            "Epoch 71/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.3297 - loss: 2.4008 - val_accuracy: 0.3513 - val_loss: 2.3175\n",
            "Epoch 72/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3500 - loss: 2.3545 - val_accuracy: 0.3569 - val_loss: 2.3224\n",
            "Epoch 73/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3342 - loss: 2.3746 - val_accuracy: 0.3420 - val_loss: 2.3277\n",
            "Epoch 74/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.3506 - loss: 2.3452 - val_accuracy: 0.3634 - val_loss: 2.3046\n",
            "Epoch 75/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3376 - loss: 2.3580 - val_accuracy: 0.3680 - val_loss: 2.3316\n",
            "Epoch 76/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3567 - loss: 2.3152 - val_accuracy: 0.3690 - val_loss: 2.2989\n",
            "Epoch 77/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3777 - loss: 2.2241 - val_accuracy: 0.3680 - val_loss: 2.2556\n",
            "Epoch 78/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.3741 - loss: 2.2618 - val_accuracy: 0.3810 - val_loss: 2.2564\n",
            "Epoch 79/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.3535 - loss: 2.3087 - val_accuracy: 0.3717 - val_loss: 2.3229\n",
            "Epoch 80/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.3663 - loss: 2.2665 - val_accuracy: 0.3727 - val_loss: 2.3035\n",
            "Epoch 81/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.3672 - loss: 2.2350 - val_accuracy: 0.3755 - val_loss: 2.2406\n",
            "Epoch 82/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.3754 - loss: 2.2214 - val_accuracy: 0.3913 - val_loss: 2.2138\n",
            "Epoch 83/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.3854 - loss: 2.1997 - val_accuracy: 0.4052 - val_loss: 2.2165\n",
            "Epoch 84/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.4011 - loss: 2.1531 - val_accuracy: 0.3894 - val_loss: 2.2213\n",
            "Epoch 85/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.3913 - loss: 2.1479 - val_accuracy: 0.3829 - val_loss: 2.2342\n",
            "Epoch 86/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.3852 - loss: 2.1695 - val_accuracy: 0.3745 - val_loss: 2.2334\n",
            "Epoch 87/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.3932 - loss: 2.1638 - val_accuracy: 0.3959 - val_loss: 2.2069\n",
            "Epoch 88/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.3978 - loss: 2.1313 - val_accuracy: 0.3903 - val_loss: 2.2030\n",
            "Epoch 89/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.4107 - loss: 2.1165 - val_accuracy: 0.3727 - val_loss: 2.3412\n",
            "Epoch 90/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.4067 - loss: 2.1371 - val_accuracy: 0.3857 - val_loss: 2.2026\n",
            "Epoch 91/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4138 - loss: 2.0650 - val_accuracy: 0.4108 - val_loss: 2.1524\n",
            "Epoch 92/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4300 - loss: 2.0345 - val_accuracy: 0.4061 - val_loss: 2.1699\n",
            "Epoch 93/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4304 - loss: 2.0305 - val_accuracy: 0.4006 - val_loss: 2.1417\n",
            "Epoch 94/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.4219 - loss: 2.0660 - val_accuracy: 0.4145 - val_loss: 2.2183\n",
            "Epoch 95/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4313 - loss: 2.0406 - val_accuracy: 0.4164 - val_loss: 2.1532\n",
            "Epoch 96/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4254 - loss: 2.0112 - val_accuracy: 0.4145 - val_loss: 2.1407\n",
            "Epoch 97/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4239 - loss: 2.0210 - val_accuracy: 0.3941 - val_loss: 2.1846\n",
            "Epoch 98/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4398 - loss: 1.9880 - val_accuracy: 0.4108 - val_loss: 2.1673\n",
            "Epoch 99/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4361 - loss: 1.9855 - val_accuracy: 0.4015 - val_loss: 2.1878\n",
            "Epoch 100/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.4424 - loss: 1.9295 - val_accuracy: 0.3959 - val_loss: 2.2235\n",
            "Epoch 101/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4505 - loss: 1.9419 - val_accuracy: 0.4219 - val_loss: 2.1573\n",
            "Epoch 102/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4525 - loss: 1.9193 - val_accuracy: 0.4136 - val_loss: 2.1975\n",
            "Epoch 103/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4463 - loss: 1.9350 - val_accuracy: 0.4238 - val_loss: 2.1756\n",
            "Epoch 104/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4588 - loss: 1.9073 - val_accuracy: 0.4154 - val_loss: 2.1295\n",
            "Epoch 105/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4551 - loss: 1.8892 - val_accuracy: 0.4219 - val_loss: 2.1482\n",
            "Epoch 106/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4584 - loss: 1.8723 - val_accuracy: 0.4099 - val_loss: 2.2472\n",
            "Epoch 107/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4618 - loss: 1.8883 - val_accuracy: 0.4229 - val_loss: 2.1090\n",
            "Epoch 108/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4718 - loss: 1.8448 - val_accuracy: 0.4201 - val_loss: 2.1930\n",
            "Epoch 109/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4742 - loss: 1.8561 - val_accuracy: 0.4257 - val_loss: 2.1563\n",
            "Epoch 110/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4936 - loss: 1.7612 - val_accuracy: 0.4201 - val_loss: 2.1354\n",
            "Epoch 111/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.4774 - loss: 1.8231 - val_accuracy: 0.4247 - val_loss: 2.1085\n",
            "Epoch 112/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5022 - loss: 1.7847 - val_accuracy: 0.4182 - val_loss: 2.1748\n",
            "Epoch 113/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4870 - loss: 1.7829 - val_accuracy: 0.4257 - val_loss: 2.1642\n",
            "Epoch 114/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4838 - loss: 1.7903 - val_accuracy: 0.4294 - val_loss: 2.1269\n",
            "Epoch 115/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5018 - loss: 1.7350 - val_accuracy: 0.4396 - val_loss: 2.2093\n",
            "Epoch 116/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5022 - loss: 1.7337 - val_accuracy: 0.4349 - val_loss: 2.0893\n",
            "Epoch 117/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.4984 - loss: 1.7699 - val_accuracy: 0.4359 - val_loss: 2.1585\n",
            "Epoch 118/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5052 - loss: 1.7290 - val_accuracy: 0.4507 - val_loss: 2.0986\n",
            "Epoch 119/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4981 - loss: 1.7241 - val_accuracy: 0.4387 - val_loss: 2.1097\n",
            "Epoch 120/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5189 - loss: 1.7012 - val_accuracy: 0.4517 - val_loss: 2.1047\n",
            "Epoch 121/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5158 - loss: 1.6574 - val_accuracy: 0.4359 - val_loss: 2.1289\n",
            "Epoch 122/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5127 - loss: 1.6636 - val_accuracy: 0.4201 - val_loss: 2.2164\n",
            "Epoch 123/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5123 - loss: 1.6853 - val_accuracy: 0.4349 - val_loss: 2.1488\n",
            "Epoch 124/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5207 - loss: 1.6588 - val_accuracy: 0.4461 - val_loss: 2.1359\n",
            "Epoch 125/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5309 - loss: 1.6411 - val_accuracy: 0.4387 - val_loss: 2.1065\n",
            "Epoch 126/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5322 - loss: 1.6100 - val_accuracy: 0.4359 - val_loss: 2.1918\n",
            "Epoch 127/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5377 - loss: 1.6090 - val_accuracy: 0.4507 - val_loss: 2.1744\n",
            "Epoch 128/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5246 - loss: 1.6162 - val_accuracy: 0.4498 - val_loss: 2.1187\n",
            "Epoch 129/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5426 - loss: 1.5837 - val_accuracy: 0.4684 - val_loss: 2.0847\n",
            "Epoch 130/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5521 - loss: 1.5837 - val_accuracy: 0.4359 - val_loss: 2.1608\n",
            "Epoch 131/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.5526 - loss: 1.5275 - val_accuracy: 0.4433 - val_loss: 2.1555\n",
            "Epoch 132/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.5481 - loss: 1.5507 - val_accuracy: 0.4442 - val_loss: 2.1620\n",
            "Epoch 133/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.5483 - loss: 1.5630 - val_accuracy: 0.4517 - val_loss: 2.1211\n",
            "Epoch 134/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.5528 - loss: 1.5381 - val_accuracy: 0.4359 - val_loss: 2.1253\n",
            "Epoch 135/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5655 - loss: 1.5057 - val_accuracy: 0.4433 - val_loss: 2.1400\n",
            "Epoch 136/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5601 - loss: 1.5111 - val_accuracy: 0.4433 - val_loss: 2.1477\n",
            "Epoch 137/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5635 - loss: 1.4994 - val_accuracy: 0.4638 - val_loss: 2.1303\n",
            "Epoch 138/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5787 - loss: 1.4566 - val_accuracy: 0.4591 - val_loss: 2.1350\n",
            "Epoch 139/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5725 - loss: 1.4631 - val_accuracy: 0.4368 - val_loss: 2.1961\n",
            "Epoch 140/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5750 - loss: 1.4712 - val_accuracy: 0.4424 - val_loss: 2.1499\n",
            "Epoch 141/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5709 - loss: 1.4659 - val_accuracy: 0.4526 - val_loss: 2.1206\n",
            "Epoch 142/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5717 - loss: 1.4810 - val_accuracy: 0.4433 - val_loss: 2.2013\n",
            "Epoch 143/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5692 - loss: 1.4956 - val_accuracy: 0.4359 - val_loss: 2.2056\n",
            "Epoch 144/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.5853 - loss: 1.4385 - val_accuracy: 0.4507 - val_loss: 2.1443\n",
            "Epoch 145/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5869 - loss: 1.4202 - val_accuracy: 0.4461 - val_loss: 2.2044\n",
            "Epoch 146/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5876 - loss: 1.4097 - val_accuracy: 0.4433 - val_loss: 2.2350\n",
            "Epoch 147/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5985 - loss: 1.3731 - val_accuracy: 0.4554 - val_loss: 2.1722\n",
            "Epoch 148/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5849 - loss: 1.3921 - val_accuracy: 0.4433 - val_loss: 2.2098\n",
            "Epoch 149/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6009 - loss: 1.3514 - val_accuracy: 0.4647 - val_loss: 2.2116\n",
            "Epoch 150/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6035 - loss: 1.3654 - val_accuracy: 0.4470 - val_loss: 2.1534\n",
            "Epoch 151/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5953 - loss: 1.3807 - val_accuracy: 0.4535 - val_loss: 2.2399\n",
            "Epoch 152/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6089 - loss: 1.3112 - val_accuracy: 0.4563 - val_loss: 2.2286\n",
            "Epoch 153/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.6074 - loss: 1.3426 - val_accuracy: 0.4470 - val_loss: 2.2768\n",
            "Epoch 154/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6102 - loss: 1.3205 - val_accuracy: 0.4545 - val_loss: 2.2035\n",
            "Epoch 155/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.6093 - loss: 1.3388 - val_accuracy: 0.4535 - val_loss: 2.2253\n",
            "Epoch 156/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.5973 - loss: 1.3391 - val_accuracy: 0.4545 - val_loss: 2.2545\n",
            "Epoch 157/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.6090 - loss: 1.3233 - val_accuracy: 0.4387 - val_loss: 2.2640\n",
            "Epoch 158/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6068 - loss: 1.3721 - val_accuracy: 0.4452 - val_loss: 2.2028\n",
            "Epoch 159/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6177 - loss: 1.3034 - val_accuracy: 0.4591 - val_loss: 2.2301\n",
            "Epoch 160/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6246 - loss: 1.2853 - val_accuracy: 0.4489 - val_loss: 2.2707\n",
            "Epoch 161/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6315 - loss: 1.2612 - val_accuracy: 0.4665 - val_loss: 2.2173\n",
            "Epoch 162/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6292 - loss: 1.2526 - val_accuracy: 0.4507 - val_loss: 2.2886\n",
            "Epoch 163/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6133 - loss: 1.3095 - val_accuracy: 0.4554 - val_loss: 2.2485\n",
            "Epoch 164/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6342 - loss: 1.2493 - val_accuracy: 0.4638 - val_loss: 2.2155\n",
            "Epoch 165/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6440 - loss: 1.2317 - val_accuracy: 0.4507 - val_loss: 2.2211\n",
            "Epoch 166/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6383 - loss: 1.2185 - val_accuracy: 0.4480 - val_loss: 2.2947\n",
            "Epoch 167/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6367 - loss: 1.2236 - val_accuracy: 0.4507 - val_loss: 2.2469\n",
            "Epoch 168/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6363 - loss: 1.1903 - val_accuracy: 0.4442 - val_loss: 2.3369\n",
            "Epoch 169/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6451 - loss: 1.2021 - val_accuracy: 0.4489 - val_loss: 2.2942\n",
            "Epoch 170/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6408 - loss: 1.2010 - val_accuracy: 0.4359 - val_loss: 2.3991\n",
            "Epoch 171/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.6490 - loss: 1.1892 - val_accuracy: 0.4489 - val_loss: 2.2740\n",
            "Epoch 172/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.6481 - loss: 1.1985 - val_accuracy: 0.4647 - val_loss: 2.2314\n",
            "Epoch 173/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6693 - loss: 1.1402 - val_accuracy: 0.4638 - val_loss: 2.2719\n",
            "Epoch 174/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.6472 - loss: 1.1719 - val_accuracy: 0.4545 - val_loss: 2.2698\n",
            "Epoch 175/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6533 - loss: 1.1671 - val_accuracy: 0.4433 - val_loss: 2.3176\n",
            "Epoch 176/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.6584 - loss: 1.1610 - val_accuracy: 0.4647 - val_loss: 2.2785\n",
            "Epoch 177/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6706 - loss: 1.1013 - val_accuracy: 0.4572 - val_loss: 2.2874\n",
            "Epoch 178/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6554 - loss: 1.1430 - val_accuracy: 0.4387 - val_loss: 2.3856\n",
            "Epoch 179/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6561 - loss: 1.1748 - val_accuracy: 0.4535 - val_loss: 2.3074\n",
            "Epoch 179: early stopping\n",
            "Restoring model weights from the end of the best epoch: 129.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7eef6ffe2270>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 1. Tiền xử lý cho mô hình chuỗi\n",
        "# a. Tokenizer: Tạo vocab và chuyển text thành chuỗi chỉ số\n",
        "all_sentences = df_train['text'].to_list()\n",
        "\n",
        "tokens = set()\n",
        "for sentence in all_sentences:\n",
        "    tokens.update(sentence.split())\n",
        "\n",
        "vocab_size = len(tokens)\n",
        "# print(\"Vocab size\", vocab_size)\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<UNK>\")\n",
        "tokenizer.fit_on_texts(all_sentences)\n",
        "train_sequences = tokenizer.texts_to_sequences(all_sentences)\n",
        "test_sequences = tokenizer.texts_to_sequences(df_test['text'].to_list())\n",
        "val_sequences = tokenizer.texts_to_sequences(df_val['text'].to_list())\n",
        "# print(\"Train sequences:\", train_sequences)\n",
        "\n",
        "\n",
        "# b. Padding: Đảm bảo các chuỗi có cùng độ dài\n",
        "max_len = 50\n",
        "X_train_pad = pad_sequences(train_sequences, maxlen=max_len, padding='post')\n",
        "X_test_pad = pad_sequences(test_sequences, maxlen=max_len, padding='post')\n",
        "X_val_pad = pad_sequences(val_sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "\n",
        "# 2. Tạo ma trận trọng số cho Embedding Layer từ Word2Vec\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_dim = w2v_model.vector_size\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in w2v_model.wv:\n",
        "        embedding_matrix[i] = w2v_model.wv[word]\n",
        "\n",
        "# print(\"Embedding matrix:\", embedding_matrix)\n",
        "\n",
        "\n",
        "# 3. Xây dựng mô hình Sequential với LSTM\n",
        "lstm_model_pretrained = Sequential([\n",
        "    Embedding(\n",
        "        input_dim=vocab_size,\n",
        "        output_dim=embedding_dim,\n",
        "        weights=[embedding_matrix], # Khởi tạo trọng số\n",
        "        input_length=max_len,\n",
        "        trainable=False # Đóng băng lớp Embedding\n",
        "    ),\n",
        "    LSTM(128, dropout=0.2),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "# 4. Compile, huấn luyện (sử earlystopping)\n",
        "lstm_model_pretrained.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',  # Metric to monitor (e.g., validation loss)\n",
        "    min_delta=0.001,     # Minimum change in the monitored metric to qualify as an improvement\n",
        "    patience=50,         # Number of epochs with no improvement after which training will be stopped\n",
        "    verbose=1,           # Verbosity mode (0 for silent, 1 for updates)\n",
        "    mode='min',          # 'min' for metrics that should decrease (like loss), 'max' for metrics that should increase (like accuracy)\n",
        "    restore_best_weights=True # Restores model weights from the epoch with the best value of the monitored metric\n",
        ")\n",
        "\n",
        "lstm_model_pretrained.fit(\n",
        "    X_train_pad,\n",
        "    y_train,\n",
        "    epochs=200,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val_pad, y_val),\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "40d031c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "40d031c7",
        "outputId": "cbcf44ab-6f73-4c38-8290-05bb57834e4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5478 - loss: 1.8702\n",
            "Test accuracy: 0.4591\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.89      0.87        19\n",
            "           1       0.89      0.73      0.80        11\n",
            "           2       0.74      0.89      0.81        19\n",
            "           3       0.60      0.38      0.46         8\n",
            "           4       0.40      0.40      0.40        15\n",
            "           5       0.62      0.62      0.62        13\n",
            "           6       0.36      0.21      0.27        19\n",
            "           7       0.41      0.63      0.50        19\n",
            "           8       0.30      0.37      0.33        19\n",
            "           9       0.29      0.21      0.24        19\n",
            "          10       0.62      0.62      0.62         8\n",
            "          11       0.63      0.63      0.63        19\n",
            "          12       0.33      0.62      0.43         8\n",
            "          13       0.30      0.42      0.35        19\n",
            "          14       0.18      0.11      0.13        19\n",
            "          15       0.30      0.42      0.35        19\n",
            "          16       0.62      0.79      0.70        19\n",
            "          17       0.80      0.84      0.82        19\n",
            "          18       0.90      0.95      0.92        19\n",
            "          19       0.80      0.84      0.82        19\n",
            "          20       0.71      0.63      0.67        19\n",
            "          21       0.43      0.25      0.32        12\n",
            "          22       0.70      0.74      0.72        19\n",
            "          23       0.56      0.74      0.64        19\n",
            "          24       0.00      0.00      0.00        19\n",
            "          25       0.67      0.84      0.74        19\n",
            "          26       0.75      0.75      0.75        16\n",
            "          27       0.53      0.42      0.47        19\n",
            "          28       0.59      0.68      0.63        19\n",
            "          29       0.54      0.58      0.56        12\n",
            "          30       0.81      0.89      0.85        19\n",
            "          31       0.67      0.67      0.67         3\n",
            "          32       0.67      0.29      0.40        14\n",
            "          33       0.57      0.44      0.50         9\n",
            "          34       0.57      0.57      0.57         7\n",
            "          35       0.63      0.63      0.63        19\n",
            "          36       1.00      0.37      0.54        19\n",
            "          37       0.73      0.42      0.53        19\n",
            "          38       0.21      0.33      0.26        18\n",
            "          39       0.38      0.32      0.34        19\n",
            "          40       0.33      0.29      0.31         7\n",
            "          41       0.25      0.16      0.19        19\n",
            "          42       0.16      0.16      0.16        19\n",
            "          43       0.38      0.53      0.44        19\n",
            "          44       0.27      0.16      0.20        19\n",
            "          45       0.26      0.32      0.29        19\n",
            "          46       0.19      0.26      0.22        19\n",
            "          47       0.86      0.32      0.46        19\n",
            "          48       0.57      0.63      0.60        19\n",
            "          49       0.32      0.42      0.36        19\n",
            "          50       0.41      0.50      0.45        14\n",
            "          51       0.33      0.37      0.35        19\n",
            "          52       0.43      0.16      0.23        19\n",
            "          53       0.09      0.11      0.10        19\n",
            "          54       0.00      0.00      0.00        10\n",
            "          55       0.17      0.32      0.22        19\n",
            "          56       0.06      0.06      0.06        18\n",
            "          57       0.29      0.21      0.24        19\n",
            "          58       0.27      0.32      0.29        19\n",
            "          59       0.13      0.11      0.12        19\n",
            "          60       0.62      0.83      0.71        18\n",
            "          61       0.55      0.63      0.59        19\n",
            "          62       0.50      0.32      0.39        19\n",
            "          63       0.26      0.26      0.26        19\n",
            "\n",
            "    accuracy                           0.46      1076\n",
            "   macro avg       0.47      0.46      0.45      1076\n",
            "weighted avg       0.47      0.46      0.45      1076\n",
            "\n"
          ]
        }
      ],
      "source": [
        "loss, acc = lstm_model_pretrained.evaluate(X_test_pad, y_test)\n",
        "\n",
        "print(f\"Test accuracy: {acc:.4f}\")\n",
        "\n",
        "y_pred = lstm_model_pretrained.predict(X_test_pad)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b71e9ba",
      "metadata": {
        "id": "2b71e9ba"
      },
      "source": [
        "## 4. Embedding học từ đầu + LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "e278f876",
      "metadata": {
        "id": "e278f876"
      },
      "outputs": [],
      "source": [
        "all_sentences = df_train['text'].to_list()\n",
        "\n",
        "tokens = set()\n",
        "for sentence in all_sentences:\n",
        "    tokens.update(sentence.split())\n",
        "\n",
        "vocab_size = len(tokens)\n",
        "max_len = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "SfpkxkdIVHCF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfpkxkdIVHCF",
        "outputId": "542366ec-4b6f-4636-c647-67337a1beda9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[   9,   99,   24, ...,    0,    0,    0],\n",
              "       [ 809,   39,   36, ...,    0,    0,    0],\n",
              "       [ 606,   36,  532, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [  44,    5, 1519, ...,    0,    0,    0],\n",
              "       [ 202,    5,  386, ...,    0,    0,    0],\n",
              "       [   9,    6,    2, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_pad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "8688fb76",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8688fb76",
        "outputId": "97214d65-5e5d-4602-80d6-fe35cace4cd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.0143 - loss: 4.1492 - val_accuracy: 0.0177 - val_loss: 4.1295\n",
            "Epoch 2/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0187 - loss: 4.1363 - val_accuracy: 0.0177 - val_loss: 4.1277\n",
            "Epoch 3/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.0153 - loss: 4.1363 - val_accuracy: 0.0177 - val_loss: 4.1258\n",
            "Epoch 4/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0160 - loss: 4.1305 - val_accuracy: 0.0177 - val_loss: 4.1253\n",
            "Epoch 5/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0160 - loss: 4.1370 - val_accuracy: 0.0177 - val_loss: 4.1247\n",
            "Epoch 6/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0175 - loss: 4.1313 - val_accuracy: 0.0177 - val_loss: 4.1248\n",
            "Epoch 7/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.0173 - loss: 4.1332 - val_accuracy: 0.0177 - val_loss: 4.1250\n",
            "Epoch 8/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.0179 - loss: 4.1294 - val_accuracy: 0.0177 - val_loss: 4.1240\n",
            "Epoch 9/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.0169 - loss: 4.1298 - val_accuracy: 0.0177 - val_loss: 4.1254\n",
            "Epoch 10/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0178 - loss: 4.1350 - val_accuracy: 0.0177 - val_loss: 4.1239\n",
            "Epoch 11/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0176 - loss: 4.1286 - val_accuracy: 0.0177 - val_loss: 4.1249\n",
            "Epoch 12/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0159 - loss: 4.1292 - val_accuracy: 0.0177 - val_loss: 4.1242\n",
            "Epoch 13/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0142 - loss: 4.1277 - val_accuracy: 0.0177 - val_loss: 4.1245\n",
            "Epoch 14/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.0188 - loss: 4.1306 - val_accuracy: 0.0177 - val_loss: 4.1243\n",
            "Epoch 15/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0163 - loss: 4.1259 - val_accuracy: 0.0177 - val_loss: 4.1245\n",
            "Epoch 16/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0187 - loss: 4.1309 - val_accuracy: 0.0177 - val_loss: 4.1244\n",
            "Epoch 17/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0192 - loss: 4.1264 - val_accuracy: 0.0177 - val_loss: 4.1246\n",
            "Epoch 18/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0159 - loss: 4.1296 - val_accuracy: 0.0177 - val_loss: 4.1249\n",
            "Epoch 19/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0183 - loss: 4.1265 - val_accuracy: 0.0177 - val_loss: 4.1241\n",
            "Epoch 20/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.0155 - loss: 4.1274 - val_accuracy: 0.0177 - val_loss: 4.1247\n",
            "Epoch 21/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0139 - loss: 4.1329 - val_accuracy: 0.0177 - val_loss: 4.1238\n",
            "Epoch 22/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.0152 - loss: 4.1302 - val_accuracy: 0.0177 - val_loss: 4.1242\n",
            "Epoch 23/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0147 - loss: 4.1279 - val_accuracy: 0.0177 - val_loss: 4.1239\n",
            "Epoch 24/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0137 - loss: 4.1295 - val_accuracy: 0.0177 - val_loss: 4.1240\n",
            "Epoch 25/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.0119 - loss: 4.1318 - val_accuracy: 0.0177 - val_loss: 4.1237\n",
            "Epoch 26/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.0165 - loss: 4.1293 - val_accuracy: 0.0177 - val_loss: 4.1240\n",
            "Epoch 27/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0176 - loss: 4.1333 - val_accuracy: 0.0177 - val_loss: 4.1237\n",
            "Epoch 28/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0156 - loss: 4.1326 - val_accuracy: 0.0177 - val_loss: 4.1238\n",
            "Epoch 29/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0159 - loss: 4.1308 - val_accuracy: 0.0177 - val_loss: 4.1239\n",
            "Epoch 30/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0148 - loss: 4.1289 - val_accuracy: 0.0177 - val_loss: 4.1241\n",
            "Epoch 31/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.0189 - loss: 4.1293 - val_accuracy: 0.0177 - val_loss: 4.1239\n",
            "Epoch 32/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.0146 - loss: 4.1315 - val_accuracy: 0.0177 - val_loss: 4.1239\n",
            "Epoch 33/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0171 - loss: 4.1278 - val_accuracy: 0.0177 - val_loss: 4.1242\n",
            "Epoch 34/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0176 - loss: 4.1300 - val_accuracy: 0.0177 - val_loss: 4.1237\n",
            "Epoch 35/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0175 - loss: 4.1308 - val_accuracy: 0.0177 - val_loss: 4.1237\n",
            "Epoch 36/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.0157 - loss: 4.1303 - val_accuracy: 0.0177 - val_loss: 4.1238\n",
            "Epoch 37/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.0157 - loss: 4.1305 - val_accuracy: 0.0177 - val_loss: 4.1237\n",
            "Epoch 38/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.0161 - loss: 4.1311 - val_accuracy: 0.0177 - val_loss: 4.1236\n",
            "Epoch 39/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0140 - loss: 4.1277 - val_accuracy: 0.0177 - val_loss: 4.1240\n",
            "Epoch 40/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0163 - loss: 4.1308 - val_accuracy: 0.0177 - val_loss: 4.1241\n",
            "Epoch 41/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.0160 - loss: 4.1299 - val_accuracy: 0.0177 - val_loss: 4.1240\n",
            "Epoch 42/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.0157 - loss: 4.1317 - val_accuracy: 0.0177 - val_loss: 4.1235\n",
            "Epoch 43/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0159 - loss: 4.1276 - val_accuracy: 0.0177 - val_loss: 4.1239\n",
            "Epoch 44/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0181 - loss: 4.1289 - val_accuracy: 0.0177 - val_loss: 4.1239\n",
            "Epoch 45/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0171 - loss: 4.1267 - val_accuracy: 0.0177 - val_loss: 4.1241\n",
            "Epoch 46/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.0170 - loss: 4.1316 - val_accuracy: 0.0177 - val_loss: 4.1235\n",
            "Epoch 47/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0163 - loss: 4.1249 - val_accuracy: 0.0177 - val_loss: 4.1244\n",
            "Epoch 48/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0132 - loss: 4.1266 - val_accuracy: 0.0177 - val_loss: 4.1239\n",
            "Epoch 49/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0150 - loss: 4.1256 - val_accuracy: 0.0177 - val_loss: 4.1243\n",
            "Epoch 50/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0167 - loss: 4.1311 - val_accuracy: 0.0177 - val_loss: 4.1236\n",
            "Epoch 51/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.0188 - loss: 4.1270 - val_accuracy: 0.0177 - val_loss: 4.1242\n",
            "Epoch 52/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.0147 - loss: 4.1309 - val_accuracy: 0.0177 - val_loss: 4.1236\n",
            "Epoch 53/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0169 - loss: 4.1304 - val_accuracy: 0.0177 - val_loss: 4.1237\n",
            "Epoch 54/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.0140 - loss: 4.1325 - val_accuracy: 0.0177 - val_loss: 4.1236\n",
            "Epoch 55/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.0155 - loss: 4.1296 - val_accuracy: 0.0177 - val_loss: 4.1238\n",
            "Epoch 56/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0177 - loss: 4.1280 - val_accuracy: 0.0177 - val_loss: 4.1237\n",
            "Epoch 57/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.0164 - loss: 4.1289 - val_accuracy: 0.0177 - val_loss: 4.1236\n",
            "Epoch 58/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0160 - loss: 4.1256 - val_accuracy: 0.0177 - val_loss: 4.1239\n",
            "Epoch 59/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0152 - loss: 4.1290 - val_accuracy: 0.0177 - val_loss: 4.1236\n",
            "Epoch 60/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.0192 - loss: 4.1292 - val_accuracy: 0.0177 - val_loss: 4.1237\n",
            "Epoch 61/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.0169 - loss: 4.1299 - val_accuracy: 0.0177 - val_loss: 4.1236\n",
            "Epoch 62/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.0152 - loss: 4.1278 - val_accuracy: 0.0177 - val_loss: 4.1238\n",
            "Epoch 63/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0179 - loss: 4.1303 - val_accuracy: 0.0177 - val_loss: 4.1236\n",
            "Epoch 64/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0170 - loss: 4.1262 - val_accuracy: 0.0177 - val_loss: 4.1237\n",
            "Epoch 65/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0140 - loss: 4.1302 - val_accuracy: 0.0177 - val_loss: 4.1237\n",
            "Epoch 66/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0178 - loss: 4.1286 - val_accuracy: 0.0177 - val_loss: 4.1239\n",
            "Epoch 67/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0157 - loss: 4.1313 - val_accuracy: 0.0177 - val_loss: 4.1236\n",
            "Epoch 68/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.0152 - loss: 4.1317 - val_accuracy: 0.0177 - val_loss: 4.1236\n",
            "Epoch 69/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.0179 - loss: 4.1290 - val_accuracy: 0.0177 - val_loss: 4.1238\n",
            "Epoch 70/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0153 - loss: 4.1296 - val_accuracy: 0.0177 - val_loss: 4.1236\n",
            "Epoch 71/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0164 - loss: 4.1261 - val_accuracy: 0.0177 - val_loss: 4.1241\n",
            "Epoch 72/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.0134 - loss: 4.1302 - val_accuracy: 0.0177 - val_loss: 4.1236\n",
            "Epoch 73/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.0179 - loss: 4.1291 - val_accuracy: 0.0177 - val_loss: 4.1236\n",
            "Epoch 74/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0179 - loss: 4.1290 - val_accuracy: 0.0177 - val_loss: 4.1235\n",
            "Epoch 75/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0169 - loss: 4.1235 - val_accuracy: 0.0177 - val_loss: 4.1240\n",
            "Epoch 76/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0144 - loss: 4.1302 - val_accuracy: 0.0177 - val_loss: 4.1238\n",
            "Epoch 77/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0131 - loss: 4.1301 - val_accuracy: 0.0177 - val_loss: 4.1238\n",
            "Epoch 78/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.0160 - loss: 4.1320 - val_accuracy: 0.0177 - val_loss: 4.1236\n",
            "Epoch 79/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0149 - loss: 4.1310 - val_accuracy: 0.0177 - val_loss: 4.1236\n",
            "Epoch 80/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.0163 - loss: 4.1289 - val_accuracy: 0.0177 - val_loss: 4.1239\n",
            "Epoch 81/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.0167 - loss: 4.1283 - val_accuracy: 0.0177 - val_loss: 4.1238\n",
            "Epoch 82/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.0170 - loss: 4.1253 - val_accuracy: 0.0177 - val_loss: 4.1239\n",
            "Epoch 83/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.0184 - loss: 4.1270 - val_accuracy: 0.0177 - val_loss: 4.1237\n",
            "Epoch 84/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0151 - loss: 4.1306 - val_accuracy: 0.0177 - val_loss: 4.1236\n",
            "Epoch 85/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0158 - loss: 4.1291 - val_accuracy: 0.0177 - val_loss: 4.1237\n",
            "Epoch 86/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0165 - loss: 4.1228 - val_accuracy: 0.0177 - val_loss: 4.1241\n",
            "Epoch 87/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0165 - loss: 4.1313 - val_accuracy: 0.0177 - val_loss: 4.1237\n",
            "Epoch 88/200\n",
            "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.0196 - loss: 4.1301 - val_accuracy: 0.0177 - val_loss: 4.1238\n",
            "Epoch 88: early stopping\n",
            "Restoring model weights from the end of the best epoch: 38.\n"
          ]
        }
      ],
      "source": [
        "# 4. Xây dựng mô hình\n",
        "lstm_model_scratch = Sequential([\n",
        "    Embedding(\n",
        "        input_dim=vocab_size,\n",
        "        output_dim=100,\n",
        "        input_length=max_len\n",
        "    ),\n",
        "    LSTM(128, dropout=0.2),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "lstm_model_scratch.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=0.001,\n",
        "    patience=50,\n",
        "    verbose=1,\n",
        "    mode='min',\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = lstm_model_scratch.fit(\n",
        "    X_train_pad, y_train,\n",
        "    epochs=200,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val_pad, y_val),\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "ht_BCRy7QiMB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ht_BCRy7QiMB",
        "outputId": "96ec19ca-592c-451b-ed37-f3297935fe1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0552 - loss: 4.1512\n",
            "Test accuracy: 0.0177\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        19\n",
            "           1       0.00      0.00      0.00        11\n",
            "           2       0.02      1.00      0.03        19\n",
            "           3       0.00      0.00      0.00         8\n",
            "           4       0.00      0.00      0.00        15\n",
            "           5       0.00      0.00      0.00        13\n",
            "           6       0.00      0.00      0.00        19\n",
            "           7       0.00      0.00      0.00        19\n",
            "           8       0.00      0.00      0.00        19\n",
            "           9       0.00      0.00      0.00        19\n",
            "          10       0.00      0.00      0.00         8\n",
            "          11       0.00      0.00      0.00        19\n",
            "          12       0.00      0.00      0.00         8\n",
            "          13       0.00      0.00      0.00        19\n",
            "          14       0.00      0.00      0.00        19\n",
            "          15       0.00      0.00      0.00        19\n",
            "          16       0.00      0.00      0.00        19\n",
            "          17       0.00      0.00      0.00        19\n",
            "          18       0.00      0.00      0.00        19\n",
            "          19       0.00      0.00      0.00        19\n",
            "          20       0.00      0.00      0.00        19\n",
            "          21       0.00      0.00      0.00        12\n",
            "          22       0.00      0.00      0.00        19\n",
            "          23       0.00      0.00      0.00        19\n",
            "          24       0.00      0.00      0.00        19\n",
            "          25       0.00      0.00      0.00        19\n",
            "          26       0.00      0.00      0.00        16\n",
            "          27       0.00      0.00      0.00        19\n",
            "          28       0.00      0.00      0.00        19\n",
            "          29       0.00      0.00      0.00        12\n",
            "          30       0.00      0.00      0.00        19\n",
            "          31       0.00      0.00      0.00         3\n",
            "          32       0.00      0.00      0.00        14\n",
            "          33       0.00      0.00      0.00         9\n",
            "          34       0.00      0.00      0.00         7\n",
            "          35       0.00      0.00      0.00        19\n",
            "          36       0.00      0.00      0.00        19\n",
            "          37       0.00      0.00      0.00        19\n",
            "          38       0.00      0.00      0.00        18\n",
            "          39       0.00      0.00      0.00        19\n",
            "          40       0.00      0.00      0.00         7\n",
            "          41       0.00      0.00      0.00        19\n",
            "          42       0.00      0.00      0.00        19\n",
            "          43       0.00      0.00      0.00        19\n",
            "          44       0.00      0.00      0.00        19\n",
            "          45       0.00      0.00      0.00        19\n",
            "          46       0.00      0.00      0.00        19\n",
            "          47       0.00      0.00      0.00        19\n",
            "          48       0.00      0.00      0.00        19\n",
            "          49       0.00      0.00      0.00        19\n",
            "          50       0.00      0.00      0.00        14\n",
            "          51       0.00      0.00      0.00        19\n",
            "          52       0.00      0.00      0.00        19\n",
            "          53       0.00      0.00      0.00        19\n",
            "          54       0.00      0.00      0.00        10\n",
            "          55       0.00      0.00      0.00        19\n",
            "          56       0.00      0.00      0.00        18\n",
            "          57       0.00      0.00      0.00        19\n",
            "          58       0.00      0.00      0.00        19\n",
            "          59       0.00      0.00      0.00        19\n",
            "          60       0.00      0.00      0.00        18\n",
            "          61       0.00      0.00      0.00        19\n",
            "          62       0.00      0.00      0.00        19\n",
            "          63       0.00      0.00      0.00        19\n",
            "\n",
            "    accuracy                           0.02      1076\n",
            "   macro avg       0.00      0.02      0.00      1076\n",
            "weighted avg       0.00      0.02      0.00      1076\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "loss, acc = lstm_model_scratch.evaluate(X_test_pad, y_test)\n",
        "\n",
        "print(f\"Test accuracy: {acc:.4f}\")\n",
        "\n",
        "y_pred = lstm_model_scratch.predict(X_test_pad)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0OJLZ5jiONGb",
      "metadata": {
        "id": "0OJLZ5jiONGb"
      },
      "source": [
        "# Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "30ae3d63",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30ae3d63",
        "outputId": "70f22336-4cc2-4d50-c4e2-193e531e8700"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ground true:\n",
            "['reminder_create', 'weather_query', 'flight_search']\n",
            "Logistic Regression:\n",
            "['calendar_set' 'weather_query' 'general_negate']\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Word2vec + Dense:\n",
            "['email_query' 'weather_query' 'email_sendemail']\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "Embedding (Pretrained) + LSTM:\n",
            "['takeaway_query' 'weather_query' 'social_post']\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Embedding (Scratch) + LSTM:\n",
            "['alarm_set' 'alarm_set' 'alarm_set']\n"
          ]
        }
      ],
      "source": [
        "def transform_to_vector(texts, model):\n",
        "    vectors = np.array(\n",
        "        [sentence_to_avg_vector(text, model) for text in texts],\n",
        "        dtype='float32'\n",
        "    )\n",
        "    return vectors\n",
        "\n",
        "texts = [\n",
        "    \"can you remind me to not call my mom\",\n",
        "    \"is it going to be sunny or rainy tomorrow\",\n",
        "    \"find a flight from new york to london but not through paris\"\n",
        "]\n",
        "labels = ['reminder_create', 'weather_query', 'flight_search']\n",
        "\n",
        "print(\"Ground true:\")\n",
        "print(labels)\n",
        "\n",
        "\n",
        "y_pred = tfidf_lr_pipeline.predict(texts)\n",
        "label_pred = le.inverse_transform(y_pred)\n",
        "print(\"Logistic Regression:\")\n",
        "print(label_pred)\n",
        "\n",
        "y_pred = model.predict(transform_to_vector(texts, w2v_model))\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "label_pred = le.inverse_transform(y_pred)\n",
        "print(\"Word2vec + Dense:\")\n",
        "print(label_pred)\n",
        "\n",
        "max_len = max([len(text) for text in texts])\n",
        "text_sequences = tokenizer.texts_to_sequences(texts)\n",
        "texts_pad = pad_sequences(text_sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "y_pred = lstm_model_pretrained.predict(texts_pad)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "label_pred = le.inverse_transform(y_pred)\n",
        "print(\"Embedding (Pretrained) + LSTM:\")\n",
        "print(label_pred)\n",
        "\n",
        "\n",
        "y_pred = lstm_model_scratch.predict(texts_pad)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "label_pred = le.inverse_transform(y_pred)\n",
        "print(\"Embedding (Scratch) + LSTM:\")\n",
        "print(label_pred)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "538326b1",
      "metadata": {
        "id": "538326b1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c2143a8",
      "metadata": {
        "id": "1c2143a8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a64b9db3",
      "metadata": {
        "id": "a64b9db3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Cz_reXJ_Ebox",
      "metadata": {
        "id": "Cz_reXJ_Ebox"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1YPgvAI9Ebox",
      "metadata": {
        "id": "1YPgvAI9Ebox"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
